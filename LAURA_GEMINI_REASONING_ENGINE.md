# Laura - Motor de Razonamiento Gemini 2.5 Flash

## Descripci√≥n

Laura ahora utiliza **Gemini 2.5 Flash** como motor de razonamiento para planificar y ejecutar tareas de monitoreo de redes sociales con mayor precisi√≥n y contexto.

## Caracter√≠sticas

### üß† Motor de Razonamiento Inteligente
- **Modelo**: Gemini 1.5 Flash (alias estable)
- **Temperatura**: 0.2 (precisi√≥n optimizada)
- **Tokens m√°ximos**: 1024
- **Latencia esperada**: 300-600ms

### üéØ Planificaci√≥n Inteligente
Laura puede ahora:
1. **Analizar intenciones** del usuario
2. **Elegir herramientas** apropiadas autom√°ticamente
3. **Solicitar aclaraciones** cuando sea necesario
4. **Generar planes** detallados con razonamiento

### üìä M√©tricas y Monitoreo
- Latencia de respuesta en tiempo real
- Conteo de tokens utilizados
- Timestamps de ejecuci√≥n
- Logging detallado opcional

## Configuraci√≥n

### Variables de Entorno
```bash
# Requerida
GEMINI_API_KEY=tu_api_key_aqui

# Opcional - Habilitar modo verbose
LAURA_VERBOSE_MODE=true
```

### Obtener API Key
1. Visita [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Crea un nuevo proyecto
3. Genera una API key
4. Agrega la key a tu archivo `.env`

## Uso

### Autom√°tico
El motor de razonamiento se activa autom√°ticamente en las siguientes situaciones:
- Consultas de monitoreo social
- An√°lisis de perfiles
- B√∫squedas web
- Monitoreo general de tendencias

### Casos de Uso

#### 1. Intenci√≥n Clara ‚Üí Ejecuci√≥n Directa
```
Usuario: "¬øQu√© dicen sobre la ley de protecci√≥n animal?"
Laura: Analiza contexto ‚Üí Planifica b√∫squeda ‚Üí Ejecuta nitter_context
```

#### 2. Intenci√≥n Ambigua ‚Üí Solicitud de Aclaraci√≥n
```
Usuario: "¬øQu√© est√° pasando?"
Laura: Detecta ambig√ºedad ‚Üí Solicita especificaci√≥n ‚Üí Espera respuesta
```

#### 3. An√°lisis de Perfil Espec√≠fico
```
Usuario: "Analiza @CongresoGt"
Laura: Identifica perfil ‚Üí Planifica monitoreo ‚Üí Ejecuta nitter_profile
```

## Herramientas Disponibles

### `nitter_context(q, location, limit)`
- **Prop√≥sito**: An√°lisis de conversaciones y tendencias
- **Par√°metros**: 
  - `q`: Query de b√∫squeda
  - `location`: Ubicaci√≥n geogr√°fica
  - `limit`: N√∫mero m√°ximo de resultados

### `nitter_profile(username, limit)`
- **Prop√≥sito**: Monitoreo de usuarios espec√≠ficos
- **Par√°metros**:
  - `username`: Nombre de usuario (sin @)
  - `limit`: N√∫mero m√°ximo de tweets

### `perplexity_search(query)`
- **Prop√≥sito**: B√∫squeda web y noticias actualizadas
- **Par√°metros**:
  - `query`: Consulta de b√∫squeda

## Estructura de Respuesta

### Plan de Ejecuci√≥n
```json
{
  "plan": {
    "action": "direct_execution|needs_clarification",
    "tool": "nitter_context|nitter_profile|perplexity_search",
    "args": {...},
    "reasoning": "Explicaci√≥n del razonamiento"
  },
  "follow_up": "Pregunta de aclaraci√≥n o null",
  "thought": "An√°lisis interno del contexto",
  "_metrics": {
    "latency_ms": 450,
    "timestamp": "2025-01-10T...",
    "model": "gemini-1.5-flash",
    "tokens_used": 156
  }
}
```

## Modo Verbose

### Activaci√≥n
```bash
# Variable de entorno
export LAURA_VERBOSE_MODE=true

# O en c√≥digo
const plan = await laura.buildLLMPlan(intent, extra, { verbose: true });
```

### Informaci√≥n Adicional
- Input completo del usuario
- Mensajes enviados al LLM
- Respuesta raw del modelo
- Plan parseado detallado
- Razonamiento interno
- M√©tricas de performance

## Pruebas

### Ejecutar Pruebas End-to-End
```bash
node test-laura-gemini-reasoning.js
```

### Casos de Prueba
1. **Intenci√≥n clara**: Ley de protecci√≥n animal
2. **Intenci√≥n ambigua**: "¬øQu√© est√° pasando?"
3. **An√°lisis de perfil**: @CongresoGt
4. **Prueba directa**: buildLLMPlan
5. **Verificaci√≥n de m√©tricas**: Latencia y tokens

## Fallback y Manejo de Errores

### Estrategia de Fallback
Si el motor de razonamiento falla:
1. **Log del error** detallado
2. **Plan b√°sico** autom√°tico
3. **Continuaci√≥n** de la ejecuci√≥n
4. **M√©tricas de error** registradas

### Plan de Fallback
```json
{
  "plan": {
    "action": "direct_execution",
    "tool": "nitter_context",
    "args": {"q": "intent", "location": "guatemala", "limit": 10},
    "reasoning": "Plan de fallback debido a error en LLM"
  },
  "follow_up": null,
  "thought": "Error en generaci√≥n de plan, usando estrategia b√°sica"
}
```

## Optimizaci√≥n

### Prompt Engineering
- **Instrucciones expl√≠citas** para formato JSON
- **Ejemplos few-shot** espec√≠ficos
- **Contexto guatemalteco** optimizado
- **Validaci√≥n** de estructura

### Performance
- **Temperatura baja** (0.2) para precisi√≥n
- **Tokens limitados** (1024) para eficiencia
- **Timeout** impl√≠cito del modelo
- **Retry** autom√°tico en caso de error

## Monitoreo y Logs

### M√©tricas Registradas
```
[LAURA] üß† Gemini 2.5 Flash - Latencia: 450ms
[LAURA] üß† Tokens estimados: 156 tokens
[LAURA] üß† Prompt tokens: 892 tokens
```

### Modo Verbose
```
[LAURA] üß† Verbose Mode - Input Intent: "¬øQu√© dicen sobre sismos?"
[LAURA] üß† Verbose Mode - Thought: "Consulta espec√≠fica sobre sismos..."
[LAURA] üß† Verbose Mode - Reasoning: "Uso nitter_context con t√©rminos espec√≠ficos..."
```

## Arquitectura

### Flujo de Ejecuci√≥n
```
Usuario ‚Üí AgentesService ‚Üí LauraAgent ‚Üí buildLLMPlan ‚Üí geminiChat ‚Üí executeTask ‚Üí Resultado
```

### Integraci√≥n
- **Activaci√≥n autom√°tica** en tareas habilitadas
- **Compatibilidad** con sistema existente
- **Preservaci√≥n** de funcionalidad cl√°sica
- **M√©tricas** transparentes

## Consideraciones

### Costos
- Gemini 1.5 Flash es **gratuito** hasta cierto l√≠mite
- Monitoreo de tokens para **control de costos**
- Fallback autom√°tico para **continuidad**

### Seguridad
- API key en **variables de entorno**
- **No logging** de informaci√≥n sensible
- Validaci√≥n de **estructura** de respuesta

### Rendimiento
- Latencia optimizada (~300-600ms)
- **Paralelizaci√≥n** con otras tareas
- **Timeout** autom√°tico del modelo
- **Caching** a nivel de modelo

## Ejemplo Completo

```javascript
// Consulta del usuario
const userQuery = "¬øQu√© dicen sobre la ley de protecci√≥n animal en Guatemala?";

// Ejecuci√≥n autom√°tica
const result = await agentesService.orchestrateQuery(userQuery, user);

// Respuesta con razonamiento
{
  "laura_findings": [{
    "agent": "Laura",
    "execution_strategy": ["gemini_reasoned_execution"],
    "llm_reasoning": "Uso nitter_context con t√©rminos espec√≠ficos...",
    "llm_thought": "Consulta clara sobre tema legislativo...",
    "findings": {
      "trend": "ley protecci√≥n animal Guatemala",
      "mentions": 45,
      "sentiment": 0.6,
      "top_posts": [...]
    }
  }]
}
```

## Pr√≥ximos Pasos

1. **Refinamiento** de prompts basado en uso real
2. **M√©tricas avanzadas** de calidad de respuesta
3. **Integraci√≥n** con sistema de memoria
4. **Optimizaci√≥n** de costos y performance
5. **Expansi√≥n** a otros agentes (Robert)

---

**Nota**: Este motor de razonamiento mantiene total compatibilidad con el sistema existente y proporciona capacidades avanzadas de planificaci√≥n y ejecuci√≥n para Laura.