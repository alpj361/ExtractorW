const { GoogleGenerativeAI } = require('@google/generative-ai');
const { createClient } = require('@supabase/supabase-js');
const supabaseUtil = require('../utils/supabase');
const { analyzeDocument } = require('./documentAnalysis');
let supabase = supabaseUtil;

// Instanciar Gemini para an√°lisis de texto
const genai = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// Si existe clave service_role, usarla para omitir RLS en inserciones
if (process.env.SUPABASE_SERVICE_ROLE_KEY) {
  const SUPABASE_URL = process.env.SUPABASE_URL;
  supabase = createClient(SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY, {
    auth: { persistSession: false },
    db: { schema: 'public' }
  });
}

/**
 * Genera un prompt estructurado para extraer tarjetas de informaci√≥n relevante ("capturados")
 * desde la transcripci√≥n de audio, adapt√°ndose autom√°ticamente al tipo de contenido.
 * @param {string} transcription - Texto completo de la transcripci√≥n
 */
function buildPrompt(transcription) {
  return `Eres un sistema experto en an√°lisis de transcripciones de contenido en espa√±ol. Analiza la siguiente transcripci√≥n y DETECTA autom√°ticamente el tipo de contenido, luego EXTRAE TODA la informaci√≥n relevante seg√∫n el contexto identificado.

TIPOS DE CONTENIDO Y QU√â EXTRAER:

üîç INVESTIGATIVO (casos, auditor√≠as, investigaciones):
- Hallazgos, irregularidades, problemas detectados
- Corrupci√≥n, malversaci√≥n, mala gesti√≥n
- Proyectos fallidos, gastos excesivos
- Evidencias, testimonios, datos comprometedores

üì∞ INFORMATIVO (noticias, reportes, datos):
- Eventos importantes, anuncios, declaraciones
- Estad√≠sticas, cifras, datos relevantes
- Cambios, nuevas pol√≠ticas, decisiones
- Hechos verificables y fechas importantes

üìö EDUCATIVO (tutoriales, explicaciones, capacitaciones):
- Conceptos clave, definiciones importantes
- Procesos, metodolog√≠as, pasos a seguir
- Herramientas, recursos, recomendaciones
- Lecciones aprendidas, mejores pr√°cticas

üíº COMERCIAL (productos, servicios, ventas):
- Productos/servicios mencionados, precios
- Ofertas, promociones, descuentos
- Empresas, marcas, contactos
- Oportunidades de negocio, inversiones

üë§ PERSONAL (experiencias, opiniones, historias):
- Experiencias significativas, an√©cdotas
- Opiniones importantes, recomendaciones
- Logros, fracasos, lecciones de vida
- Contactos, relaciones, colaboraciones

INSTRUCCIONES:
1. DETECTA autom√°ticamente el tipo de contenido predominante
2. ADAPTA la extracci√≥n seg√∫n el contexto identificado
3. EXTRAE informaci√≥n espec√≠fica y relevante para ese tipo
4. Si hay m√∫ltiples tipos, incluye informaci√≥n de todos

FORMATO DE RESPUESTA:
Devuelve **exclusivamente** un ARRAY JSON. **No** incluyas comentarios ni formateo Markdown.

Cada elemento debe tener **exactamente** estas claves (usa null si no aplica):
- title (string) - T√≠tulo corto (‚â§ 60 caracteres) que describa el hallazgo
- entity (string) - Persona, instituci√≥n, empresa o entidad mencionada
- amount (number) - Cantidad de dinero relevante. Si la cifra NO es dinero (p.ej. "286 obras"), pon null.
- currency (string) - Moneda si aplica (ej: "GTQ", "USD", "EUR")
- item_count (number) - Un conteo de unidades (obras, proyectos, v√≠ctimas, etc.). Usa null si no corresponde.
- city (string) - Ciudad, lugar o ubicaci√≥n mencionada
- department (string) - Departamento del pa√≠s (ej: Guatemala, Sacatep√©quez, Quetzaltenango), √°rea geogr√°fica o regi√≥n administrativa
- pais (string) - Pa√≠s mencionado (ej: Guatemala, Honduras, El Salvador, M√©xico)
- discovery (string) - Tipo de hallazgo, informaci√≥n o dato extra√≠do
- source (string) - Extracto de m√°ximo 120 caracteres de la transcripci√≥n
- start_date (string) - Fecha mencionada en formato YYYY-MM-DD o null
- duration_days (number) - Duraci√≥n en d√≠as si se menciona
- description (string) - Resumen conciso del punto extra√≠do (‚â§ 150 caracteres)

Si no hay informaci√≥n relevante que extraer, devuelve un array vac√≠o [].

TRANSCRIPCI√ìN A ANALIZAR:
"""
${transcription}
"""`;
}

/**
 * Utiliza Gemini para extraer informaci√≥n de capturados como tarjetas estructuradas.
 * @param {string} transcription
 * @returns {Promise<Array<Object>>}
 */
async function extractCapturadoCards(transcription) {
  if (!process.env.GEMINI_API_KEY) {
    throw new Error('GEMINI_API_KEY no configurada');
  }

  const prompt = buildPrompt(transcription);
  const model = genai.getGenerativeModel({ model: 'gemini-2.5-flash' });

  const result = await model.generateContent(prompt);
  let text = result.response.text().trim();

  // Eliminar bloques ```json ... ``` si existen
  text = text.replace(/```json|```/g, '').trim();

  try {
    const parsed = JSON.parse(text);
    if (Array.isArray(parsed)) {
      return parsed;
    }
    throw new Error('La respuesta no es un array JSON');
  } catch (err) {
    console.error('‚ùå Error parseando JSON de capturados:', err);
    throw new Error('No se pudo interpretar la respuesta del modelo como JSON');
  }
}

function isValidISODate(dateStr) {
  return /^\d{4}-\d{2}-\d{2}$/.test(dateStr) && !isNaN(Date.parse(dateStr));
}

// Ensure cards fields are clean
function sanitizeCard(card, codexItem = null) {
  const sanitized = { ...card };
  // title
  if (!sanitized.title || sanitized.title.trim() === '') {
    sanitized.title = sanitized.discovery ? sanitized.discovery.slice(0, 60) : null;
  }
  // start_date
  if (sanitized.start_date && !isValidISODate(sanitized.start_date)) {
    sanitized.start_date = null;
  }
  // amount numeric
  if (sanitized.amount !== null && sanitized.amount !== undefined) {
    const num = Number(sanitized.amount);
    sanitized.amount = isNaN(num) ? null : num;
  }
  // item_count derivado de amount cuando no es dinero
  if (!sanitized.currency && sanitized.amount !== null) {
    const hintText = `${card.description || ''} ${card.discovery || ''}`.toLowerCase();
    if (hintText.includes('obra') || hintText.includes('obras') || hintText.includes('proyecto') || hintText.includes('proyectos')) {
      sanitized.item_count = sanitized.amount;
      sanitized.amount = null;
      sanitized.currency = null;
    }
  }
  // duration_days numeric
  if (sanitized.duration_days !== null && sanitized.duration_days !== undefined) {
    const num = parseInt(sanitized.duration_days, 10);
    sanitized.duration_days = isNaN(num) ? null : num;
  }
  // Nueva l√≥gica: usar el t√≠tulo del archivo/documento como topic
  if (codexItem && codexItem.titulo) {
    // Extraer el tema del t√≠tulo del archivo, limpiando prefijos como "An√°lisis autom√°tico:"
    let topic = codexItem.titulo;
    if (topic.includes('An√°lisis autom√°tico:')) {
      topic = topic.replace('An√°lisis autom√°tico:', '').trim();
    }
    // Remover extensiones de archivo
    topic = topic.replace(/\.(pdf|doc|docx|txt|rtf|mp3|wav|mp4|avi|mov)$/i, '');
    sanitized.topic = topic || 'General';
  } else {
    // Fallback a las propiedades originales o General
    sanitized.topic = card.categoria || card.category || card.tipo_tema || 'General';
  }
  return sanitized;
}

/**
 * Analiza autom√°ticamente un documento si no tiene an√°lisis previo
 * @param {Object} codexItem - Item del codex
 * @param {string} userId - ID del usuario
 * @returns {Promise<string|null>} - An√°lisis del documento o null si no se pudo analizar
 */
async function ensureDocumentAnalysis(codexItem, userId) {
  // Si ya tiene an√°lisis, no hacer nada
  if (codexItem.document_analysis && codexItem.document_analysis.trim()) {
    return codexItem.document_analysis;
  }

  // Solo procesar documentos que tengan storage_path (archivo f√≠sico)
  if (codexItem.tipo !== 'documento' || !codexItem.storage_path) {
    console.log(`‚ö†Ô∏è Item ${codexItem.id} no es un documento con archivo f√≠sico, saltando an√°lisis autom√°tico`);
    return null;
  }

  console.log(`üîç Analizando documento autom√°ticamente: ${codexItem.titulo}`);

  try {
    // Construir ruta completa del archivo desde Supabase Storage
    const { data: downloadData, error: downloadError } = await supabase.storage
      .from('digitalstorage')
      .download(codexItem.storage_path);

    if (downloadError) {
      console.error(`‚ùå Error descargando archivo para an√°lisis: ${downloadError.message}`);
      return null;
    }

    // Crear archivo temporal para an√°lisis
    const fs = require('fs');
    const path = require('path');
    const tempDir = '/tmp/document_analysis';
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    const tempFileName = `${Date.now()}_${codexItem.id}_${codexItem.nombre_archivo || 'documento'}`;
    const tempFilePath = path.join(tempDir, tempFileName);

    // Escribir archivo temporal
    const arrayBuffer = await downloadData.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    fs.writeFileSync(tempFilePath, buffer);

    console.log(`üìÅ Archivo temporal creado: ${tempFilePath}`);

    // Analizar documento
    const analysisOptions = {
      titulo: `An√°lisis autom√°tico: ${codexItem.titulo}`,
      descripcion: `An√°lisis autom√°tico generado durante extracci√≥n de hallazgos`,
      etiquetas: ['analisis-automatico', 'extraccion-hallazgos'],
      proyecto: codexItem.proyecto || 'Sin proyecto',
      project_id: codexItem.project_id
    };

    const analysisResult = await analyzeDocument(tempFilePath, userId, {
      ...analysisOptions,
      updateItemId: codexItem.id // guardar en el mismo codex_item
    });

    // Limpiar archivo temporal
    try {
      fs.unlinkSync(tempFilePath);
    } catch (cleanupError) {
      console.warn(`‚ö†Ô∏è No se pudo limpiar archivo temporal: ${cleanupError.message}`);
    }

    if (analysisResult.success) {
      console.log(`‚úÖ Documento analizado exitosamente: ${analysisResult.analysis.estadisticas.hallazgos_totales} hallazgos encontrados`);

      // Obtener el an√°lisis actualizado del item
      const { data: updatedItem, error: updateError } = await supabase
        .from('codex_items')
        .select('document_analysis')
        .eq('id', codexItem.id)
        .single();

      if (updateError) {
        console.error(`‚ùå Error obteniendo an√°lisis actualizado: ${updateError.message}`);
        return null;
      }

      return updatedItem.document_analysis;
    } else {
      console.error(`‚ùå Error en an√°lisis de documento: ${analysisResult.error}`);
      return null;
    }
  } catch (error) {
    console.error(`‚ùå Error en ensureDocumentAnalysis para item ${codexItem.id}:`, error.message);
    return null;
  }
}

/**
 * Crea registros en la tabla capturado_cards a partir de un codex_item.
 * @param {Object} params
 * @param {string} params.codexItemId - ID del item de Codex (con transcripci√≥n o an√°lisis de documento)
 * @param {string} params.projectId - ID del proyecto al que pertenece
 * @param {string} params.userId - ID del usuario (requerido para an√°lisis autom√°tico de documentos)
 * @returns {Promise<Array<Object>>} Registros insertados
 */
async function createCardsFromCodex({ codexItemId, projectId, userId }) {
  // 1. Obtener informaci√≥n completa del item
  const { data: codexItem, error: codexError } = await supabase
    .from('codex_items')
    .select('id, audio_transcription, document_analysis, tipo, titulo, nombre_archivo, storage_path, proyecto, project_id')
    .eq('id', codexItemId)
    .single();

  if (codexError) {
    throw new Error(`Error obteniendo codex_item: ${codexError.message}`);
  }

  if (!codexItem) {
    throw new Error('El codex_item no existe');
  }

  // 2. Determinar qu√© contenido usar para extracci√≥n
  let contentToAnalyze = null;
  let contentType = 'unknown';

  if (codexItem.audio_transcription && codexItem.audio_transcription.trim()) {
    contentToAnalyze = codexItem.audio_transcription;
    contentType = 'audio_transcription';
    console.log(`üìÑ Procesando transcripci√≥n de audio para item: ${codexItem.titulo}`);
  } else if (codexItem.document_analysis && codexItem.document_analysis.trim()) {
    contentToAnalyze = codexItem.document_analysis;
    contentType = 'document_analysis';
    console.log(`üìã Procesando an√°lisis de documento existente para item: ${codexItem.titulo}`);
  } else if (codexItem.tipo === 'documento') {
    // 3. Intentar an√°lisis autom√°tico de documento si no hay an√°lisis previo
    console.log(`üìÑ Documento sin an√°lisis detectado, intentando an√°lisis autom√°tico...`);
    if (!userId) {
      throw new Error('userId es requerido para an√°lisis autom√°tico de documentos');
    }
    
    const autoAnalysis = await ensureDocumentAnalysis(codexItem, userId);
    if (autoAnalysis) {
      contentToAnalyze = autoAnalysis;
      contentType = 'document_analysis_auto';
      console.log(`‚úÖ An√°lisis autom√°tico completado para documento: ${codexItem.titulo}`);
    } else {
      throw new Error('No se pudo generar an√°lisis autom√°tico del documento');
    }
  } else {
    throw new Error('El codex_item no contiene audio_transcription, document_analysis, ni es un documento analizable');
  }

  console.log(`üéØ Tipo de contenido detectado: ${contentType} (${contentToAnalyze.length} caracteres)`);

  // 3. Extraer tarjetas con Gemini
  const cards = await extractCapturadoCards(contentToAnalyze);

  if (!cards || cards.length === 0) {
    return [];
  }

  // 3. Obtener tarjetas existentes para evitar duplicados
  const { data: existingCards, error: existingErr } = await supabase
    .from('capturado_cards')
    .select('*')
    .eq('codex_item_id', codexItemId);

  if (existingErr) throw new Error(`Error leyendo capturado_cards existentes: ${existingErr.message}`);

  const existingFingerprints = new Set(
    (existingCards || []).map(c => `${c.entity}|${c.city}|${c.department}|${c.discovery}|${c.description}`)
  );

  // 4. Preparar datos filtrando duplicados
  const insertData = cards
    .map(raw => {
      const card = sanitizeCard(raw, codexItem);
      return {
        ...card,
        project_id: projectId,
        codex_item_id: codexItemId
      };
    })
    .filter(c => !existingFingerprints.has(`${c.entity}|${c.city}|${c.department}|${c.discovery}|${c.description}`));

  if (insertData.length === 0) return [];

  const { data: inserted, error: insertError } = await supabase
    .from('capturado_cards')
    .insert(insertData)
    .select();

  if (insertError) {
    throw new Error(`Error insertando capturado_cards: ${insertError.message}`);
  }

  return inserted;
}

/**
 * Procesa todos los codex_items de audio/video con transcripci√≥n o documentos que a√∫n no tengan capturado_cards
 * @param {string} projectId - ID del proyecto
 * @param {string} userId - ID del usuario (requerido para an√°lisis autom√°tico de documentos)
 * @param {string[]} [codexItemIds] - Opcional: Array de IDs de codex_items a procesar. Si no se provee, procesa todos los pendientes.
 */
async function bulkCreateCardsForProject(projectId, userId, codexItemIds) {
  console.log(`üîç Iniciando bulk processing para proyecto: ${projectId}`);
  
  let query = supabase
    .from('codex_items')
    .select('id, tipo, titulo, audio_transcription, document_analysis, storage_path')
    .eq('project_id', projectId);

  // Si se especifican IDs, solo procesar esos.
  if (codexItemIds && codexItemIds.length > 0) {
    console.log(`üéØ Procesando ${codexItemIds.length} items espec√≠ficos.`);
    query = query.in('id', codexItemIds);
  } else {
    // Comportamiento original: buscar todos los analizables que no han sido capturados.
    console.log('üìã Procesando todos los items pendientes del proyecto.');
    const { data: rowsCaptured } = await supabase
      .from('capturado_cards')
      .select('codex_item_id')
      .eq('project_id', projectId);
    const capturedIds = (rowsCaptured || []).map(r => r.codex_item_id);
    
    if (capturedIds.length > 0) {
      query = query.not('id', 'in', `(${capturedIds.join(',')})`);
    }

    query = query.or('audio_transcription.not.is.null,document_analysis.not.is.null,and(tipo.eq.documento,storage_path.not.is.null)');
  }

  const { data: allItems, error: errorAllItems } = await query;
  
  if (errorAllItems) {
    console.error('‚ùå Error obteniendo todos los items:', errorAllItems);
    throw errorAllItems;
  }
  
  console.log(`üìã Items a procesar: ${allItems?.length || 0}`);
  
  const pendingItems = allItems;

  let totalCards = 0;
  const processed = [];
  for (const item of pendingItems || []) {
    try {
      console.log(`‚öôÔ∏è Procesando item: ${item.id} (${item.tipo})`);
      const cards = await createCardsFromCodex({ 
        codexItemId: item.id, 
        projectId, 
        userId 
      });
      totalCards += cards.length;
      processed.push({ codex_item_id: item.id, cards_created: cards.length });
      console.log(`‚úÖ Item ${item.id} procesado: ${cards.length} cards creadas`);
    } catch (err) {
      console.error('‚ùå Error bulk capturados en item', item.id, ':', err.message);
      // Continuar con el siguiente item en lugar de fallar completamente
      processed.push({ codex_item_id: item.id, cards_created: 0, error: err.message });
    }
  }
  
  console.log(`üéØ Procesamiento completado: ${processed.length} items procesados, ${totalCards} cards totales`);
  return { processed_count: processed.length, total_cards: totalCards, details: processed };
}

module.exports = {
  createCardsFromCodex,
  bulkCreateCardsForProject
}; 