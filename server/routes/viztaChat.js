const express = require('express');
const router = express.Router();
const { verifyUserAccess } = require('../middlewares/auth');
const mcpService = require('../services/mcp');
const recentScrapesService = require('../services/recentScrapes');
const memoriesService = require('../services/memories');
const supabase = require('../utils/supabase');

// ===================================================================
// VIZTA CHAT ROUTES
// Endpoints para el chat inteligente con integraci√≥n MCP
// ===================================================================

/**
 * Post-procesa respuestas del chat para asegurar formato consistente
 */
function formatChatResponse(response, toolResult = null) {
  try {
    // Limpiar respuesta muy larga
    if (response.length > 2000) {
      console.log('‚ö†Ô∏è Respuesta muy larga, truncando...');
      response = response.substring(0, 1800) + '\n\n*[Respuesta truncada para mejor legibilidad]*';
    }

    // Asegurar que tenga formato markdown b√°sico si no lo tiene
    if (!response.includes('##') && !response.includes('###')) {
      const lines = response.split('\n').filter(line => line.trim());
      
      if (lines.length > 0) {
        let formatted = `## üìä An√°lisis\n\n`;
        formatted += lines.join('\n\n');
        
        // Agregar resumen de datos si disponible
        if (toolResult && toolResult.tweets_found) {
          formatted += `\n\n### üìä Datos analizados:\n‚Ä¢ ${toolResult.tweets_found} tweets encontrados`;
          if (toolResult.analysis_metadata?.sentiment_distribution) {
            const sentiments = Object.entries(toolResult.analysis_metadata.sentiment_distribution);
            if (sentiments.length > 0) {
              formatted += `\n‚Ä¢ Sentimientos: ${sentiments.map(([s, c]) => `${s} (${c})`).join(', ')}`;
            }
          }
        }
        
        response = formatted;
      }
    }

    // Limpiar texto muy corrido (sin espacios entre p√°rrafos)
    response = response
      .replace(/\n{3,}/g, '\n\n') // M√°ximo 2 saltos de l√≠nea consecutivos
      .replace(/(\w)(\n)(### |## |\*\*)/g, '$1\n\n$3') // Espacios antes de headers
      .replace(/(\w)(\n)(‚Ä¢ )/g, '$1\n\n$3') // Espacios antes de bullets
      .trim();

    // Asegurar que los emojis tengan espacio despu√©s
    response = response.replace(/([üìäüìàüí≠‚ö°üéØüîç])([A-Za-z])/g, '$1 $2');

    return response;

  } catch (error) {
    console.error('‚ùå Error formateando respuesta:', error);
    return response; // Devolver original si hay error
  }
}

// Cargar dependencias de forma condicional
let OpenAI, openai, uuidv4;

try {
  OpenAI = require('openai');
  const { v4 } = require('uuid');
  uuidv4 = v4;
  
  // Configurar OpenAI
  openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  });
  
  console.log('‚úÖ Dependencias de Vizta Chat cargadas correctamente');
} catch (error) {
  console.warn('‚ö†Ô∏è Dependencias de Vizta Chat no disponibles:', error.message);
  console.warn('üì¶ Instala las dependencias con: npm install openai uuid');
}

/**
 * POST /api/vizta-chat/query
 * Endpoint principal para consultas de Vizta Chat
 */
router.post('/query', verifyUserAccess, async (req, res) => {
  try {
    // Verificar que las dependencias est√©n disponibles
    if (!openai || !uuidv4) {
      // Fallback temporal sin OpenAI
      console.log('‚ö†Ô∏è Usando fallback sin OpenAI para Vizta Chat');
      
      const fallbackSessionId = sessionId || `fallback_${Date.now()}`;
      
      // Usar directamente nitter_context como herramienta por defecto
      try {
        const toolResult = await mcpService.executeTool('nitter_context', {
          q: message,
          location: 'guatemala',
          limit: 5
        }, req.user);
        
        if (toolResult.success && toolResult.tweets) {
          // Guardar en recent_scrapes
          await recentScrapesService.saveScrape({
            queryOriginal: message,
            queryClean: message,
            herramienta: 'nitter_context',
            categoria: 'General',
            tweets: toolResult.tweets,
            userId: userId,
            sessionId: fallbackSessionId,
            mcpRequestId: `fallback_${Date.now()}`,
            mcpExecutionTime: 0,
            location: 'guatemala'
          });
          
          return res.json({
            success: true,
            response: `He encontrado ${toolResult.tweets.length} tweets relacionados con "${message}". Los datos han sido guardados y est√°n disponibles para an√°lisis.`,
            toolUsed: 'nitter_context',
            toolArgs: { q: message, location: 'guatemala', limit: 5 },
            toolResult: toolResult,
            sessionId: fallbackSessionId,
            requestId: `fallback_${Date.now()}`,
            executionTime: 0,
            timestamp: new Date().toISOString(),
            mode: 'fallback'
          });
        } else {
          throw new Error('No se pudieron obtener tweets');
        }
      } catch (error) {
        return res.status(500).json({
          success: false,
          message: 'Error en modo fallback: ' + error.message,
          error: 'Instala las dependencias con: npm run install-vizta'
        });
      }
    }

    const { message, sessionId } = req.body;
    const userId = req.user.id;
    
    if (!message) {
      return res.status(400).json({
        success: false,
        message: 'El mensaje es requerido'
      });
    }

    console.log(`ü§ñ Nueva consulta Vizta Chat de usuario ${userId}: "${message}"`);

    // Generar IDs √∫nicos
    const requestId = uuidv4();
    const chatSessionId = sessionId || uuidv4();

    // 1. Guardar mensaje del usuario en memories
    await memoriesService.saveMessage({
      sessionId: chatSessionId,
      userId: userId,
      role: 'user',
      content: message,
      messageType: 'message',
      modelUsed: 'gpt-4o-mini',
      metadata: { requestId: requestId }
    });

    // 2. Obtener los √∫ltimos 10 mensajes de la conversaci√≥n para contexto
    const conversationHistory = await memoriesService.getSessionMessages(chatSessionId, 10);
    const previousMessages = memoriesService.formatMessagesForOpenAI(conversationHistory);

    // Obtener herramientas disponibles del MCP
    const availableTools = await mcpService.listAvailableTools();
    
    // Preparar funciones para GPT-4o mini
    const functions = availableTools.map(tool => {
      // Transformar par√°metros del formato MCP al formato OpenAI
      const properties = {};
      const required = [];
      
      Object.keys(tool.parameters).forEach(key => {
        const param = tool.parameters[key];
        properties[key] = {
          type: param.type,
          description: param.description
        };
        
        // Agregar constrains adicionales si existen
        if (param.min !== undefined) properties[key].minimum = param.min;
        if (param.max !== undefined) properties[key].maximum = param.max;
        if (param.default !== undefined) properties[key].default = param.default;
        
        // Agregar a required si es necesario
        if (param.required === true) {
          required.push(key);
        }
      });
      
      return {
        name: tool.name,
        description: tool.description,
        parameters: {
          type: 'object',
          properties: properties,
          required: required
        }
      };
    });

    console.log('üîç Esquema de funciones para OpenAI:', JSON.stringify(functions, null, 2));

    // 3. Preparar mensajes incluyendo historial de conversaci√≥n
    const systemMessage = {
      role: 'system',
      content: `Eres Vizta, un asistente de investigaci√≥n especializado en an√°lisis de redes sociales y tendencias en Guatemala. 

Tu trabajo es ayudar a los usuarios a obtener y analizar informaci√≥n de redes sociales usando las herramientas disponibles.

Herramientas disponibles:
${availableTools.map(tool => `- ${tool.name}: ${tool.description}`).join('\n')}

ESTRATEGIA INTELIGENTE DE B√öSQUEDA:
Cuando el usuario solicite tweets sobre un tema, NO uses literalmente sus palabras. En su lugar, piensa estrat√©gicamente:

1. EXPANDIR T√âRMINOS: Convierte consultas generales en t√©rminos espec√≠ficos
   - "marcha del orgullo" ‚Üí buscar: "Orgullo2025 OR MarchadelOrgullo OR #OrguIIoGt OR PrideGuatemala"
   - "elecciones" ‚Üí buscar: "EleccionesGt OR #Elecciones2023 OR VotoGuatemala OR TSE"
   - "gobierno" ‚Üí buscar: "GobiernoGt OR Giammattei OR BernardoArevalo OR CasaPresidencial"

2. INCLUIR HASHTAGS PROBABLES: Siempre considera hashtags relevantes
   - Para eventos: #NombreEvento2025, #EventoGt, #Guatemala
   - Para pol√≠tica: #PoliticaGt, #Guatemala, #CongresoGt
   - Para deportes: #DeporteGt, #GuatemalaFC, #Seleccion

3. CONSIDERAR VARIACIONES: Incluye sin√≥nimos y variaciones
   - T√©rminos en espa√±ol e ingl√©s cuando sea relevante
   - Abreviaciones comunes (GT, Guate, Chapin)
   - Nombres oficiales vs. nombres populares

4. USAR OPERADORES DE B√öSQUEDA: Combina t√©rminos con OR para mayor cobertura
   - Ejemplo: "OrguIIo2025 OR MarchadelOrgullo OR Pride OR LGBTI OR diversidad"

5. PENSAR EN CONTEXTO GUATEMALTECO:
   - Incluir t√©rminos espec√≠ficos de Guatemala
   - Considerar eventos actuales y fechas relevantes
   - Usar lenguaje chap√≠n cuando sea apropiado

EJEMPLOS DE TRANSFORMACI√ìN:
- Usuario: "tweets sobre la marcha del orgullo"
  ‚Üí Buscar: "Orgullo2025 OR MarchadelOrgullo OR Pride OR LGBTI OR diversidad"

- Usuario: "qu√© dicen de las elecciones"  
  ‚Üí Buscar: "EleccionesGt OR TSE OR voto OR candidatos OR #Elecciones2025"

- Usuario: "sentimiento sobre el presidente"
  ‚Üí Buscar: "BernardoArevalo OR presidente OR GobiernoGt OR CasaPresidencial"

INSTRUCCIONES ADICIONALES:
1. Analiza la consulta del usuario en el contexto de la conversaci√≥n anterior
2. Si necesitas datos de Twitter/X, usa nitter_context con t√©rminos estrat√©gicos optimizados
3. Usa un l√≠mite de 15-25 tweets para an√°lisis m√°s completo
4. Proporciona an√°lisis contextual y insights √∫tiles
5. Mant√©n un tono profesional pero amigable
6. Enf√≥cate en Guatemala cuando sea relevante
7. Recuerda el contexto de mensajes anteriores para dar respuestas coherentes

IMPORTANTE: Nunca uses los t√©rminos exactos del usuario. Siempre expande y optimiza para obtener mejores resultados.`
    };

    // Construir array de mensajes con historial
    const messagesForAI = [systemMessage];
    
    // Agregar historial previo (excluyendo el mensaje actual del usuario que ya est√° en memories)
    if (previousMessages.length > 0) {
      // Filtrar el √∫ltimo mensaje si es del usuario (evitar duplicados)
      const filteredHistory = previousMessages.slice(0, -1);
      messagesForAI.push(...filteredHistory);
    }
    
    // Agregar el mensaje actual del usuario
    messagesForAI.push({
      role: 'user',
      content: message
    });

    console.log(`üí≠ Enviando ${messagesForAI.length} mensajes a OpenAI (incluyendo ${previousMessages.length} del historial)`);

    // 4. Llamar a GPT-4o mini con function calling y contexto de conversaci√≥n
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: messagesForAI,
      functions: functions,
      function_call: 'auto',
      temperature: 0.7,
      max_tokens: 1000
    });

    const assistantMessage = completion.choices[0].message;

    // Si GPT decidi√≥ usar una funci√≥n
    if (assistantMessage.function_call) {
      const functionName = assistantMessage.function_call.name;
      const functionArgs = JSON.parse(assistantMessage.function_call.arguments);
      
      console.log(`üîß GPT decidi√≥ usar herramienta: ${functionName} con args:`, functionArgs);

      // Ejecutar la herramienta MCP
      const startTime = Date.now();
      const toolResult = await mcpService.executeTool(functionName, functionArgs, req.user);
      const executionTime = Date.now() - startTime;

      // Generar t√≠tulo autom√°tico inteligente bas√°ndose en los resultados
      let generatedTitle = functionArgs.q || message; // fallback al query original
      
      if (toolResult.success && toolResult.tweets && toolResult.tweets.length > 0) {
        try {
          const titleCompletion = await openai.chat.completions.create({
            model: 'gpt-4o-mini',
            messages: [
              {
                role: 'system',
                content: `Eres un experto en crear t√≠tulos concisos para monitoreos de redes sociales en Guatemala.

INSTRUCCIONES:
‚Ä¢ Analiza los tweets encontrados y genera un t√≠tulo descriptivo de m√°ximo 50 caracteres
‚Ä¢ El t√≠tulo debe reflejar el TEMA PRINCIPAL de los tweets, no la query original
‚Ä¢ Usa lenguaje guatemalteco cuando sea apropiado
‚Ä¢ S√© espec√≠fico: en lugar de "Tweets sobre pol√≠tica", usa "Debate Presidencial 2024" 
‚Ä¢ Si hay un evento espec√≠fico, menci√≥nalo
‚Ä¢ Si detectas una tendencia o hashtag dominante, incl√∫yelo

EJEMPLOS:
‚Ä¢ Query: "marcha del orgullo" ‚Üí T√≠tulo: "Marcha del Orgullo LGBT+ 2025"
‚Ä¢ Query: "bernardo arevalo" ‚Üí T√≠tulo: "Gobierno Ar√©valo - √öltimas Noticias"
‚Ä¢ Query: "guatemala futbol" ‚Üí T√≠tulo: "Selecci√≥n Nacional - Copa Oro"

FORMATO: Solo devuelve el t√≠tulo, sin explicaciones.

Tweets analizados: ${JSON.stringify(toolResult.tweets.slice(0, 5), null, 2)}`
              },
              {
                role: 'user',
                content: `Query original: "${message}"\nQuery expandido: "${functionArgs.q}"\n\nGenera un t√≠tulo inteligente para este monitoreo.`
              }
            ],
            temperature: 0.3,
            max_tokens: 60
          });

          const rawTitle = titleCompletion.choices[0].message.content.trim();
          // Limpiar y validar t√≠tulo
          generatedTitle = rawTitle.replace(/['"]/g, '').substring(0, 50);
          console.log(`üè∑Ô∏è T√≠tulo generado: "${generatedTitle}" (original: "${message}")`);
          
        } catch (titleError) {
          console.error('‚ö†Ô∏è Error generando t√≠tulo autom√°tico:', titleError);
          // Usar query expandido como fallback mejorado
          generatedTitle = functionArgs.q || message;
        }
      }

      // Detectar tema/grupo para agrupaci√≥n inteligente
      let detectedGroup = null;
      try {
        const groupCompletion = await openai.chat.completions.create({
          model: 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: `Analiza la b√∫squeda y clasif√≠cala en una categor√≠a para agrupaci√≥n inteligente.

CATEGOR√çAS DISPONIBLES:
‚Ä¢ "politica-guatemala" - Temas de gobierno, elecciones, pol√≠ticos guatemaltecos
‚Ä¢ "economia-guatemala" - Temas econ√≥micos, precios, empleo, mercado
‚Ä¢ "deportes-guatemala" - F√∫tbol, olimpiadas, deportes nacionales
‚Ä¢ "cultura-guatemala" - Eventos culturales, festivales, tradiciones
‚Ä¢ "social-guatemala" - Marchas, protestas, movimientos sociales
‚Ä¢ "tecnologia" - Tech, innovaci√≥n, redes sociales
‚Ä¢ "internacional" - Noticias mundiales, pol√≠tica internacional
‚Ä¢ "entretenimiento" - M√∫sica, cine, celebridades
‚Ä¢ "general" - Todo lo dem√°s

INSTRUCCIONES:
‚Ä¢ Devuelve SOLO la categor√≠a, sin explicaciones
‚Ä¢ Si hay duda, usa "general"
‚Ä¢ Prioriza categor√≠as guatemaltecas cuando sea relevante

Query: "${message}"
T√≠tulo generado: "${generatedTitle}"`
            }
          ],
          temperature: 0.1,
          max_tokens: 20
        });

        detectedGroup = groupCompletion.choices[0].message.content.trim().toLowerCase();
        console.log(`üè∑Ô∏è Grupo detectado: "${detectedGroup}"`);
        
      } catch (groupError) {
        console.error('‚ö†Ô∏è Error detectando grupo:', groupError);
        detectedGroup = 'general';
      }

      // Guardar en recent_scrapes con t√≠tulo generado y grupo
      if (toolResult.success && toolResult.tweets) {
        await recentScrapesService.saveScrape({
          queryOriginal: message,
          queryClean: functionArgs.q || message,
          generatedTitle: generatedTitle,
          detectedGroup: detectedGroup,
          herramienta: functionName,
          categoria: 'General',
          tweets: toolResult.tweets,
          userId: userId,
          sessionId: chatSessionId,
          mcpRequestId: requestId,
          mcpExecutionTime: executionTime,
          location: functionArgs.location || 'guatemala'
        });
      }

      // Generar respuesta final con contexto
      const finalCompletion = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: `Eres Vizta, un asistente de investigaci√≥n especializado en an√°lisis social de Guatemala. El usuario hizo una consulta y obtuviste datos usando la herramienta ${functionName}.

INSTRUCCIONES PARA RESPUESTA:
‚Ä¢ S√© CONCISO y DIRECTO (m√°ximo 300 palabras)
‚Ä¢ Usa formato MARKDOWN para mejor legibilidad
‚Ä¢ Estructura tu respuesta con secciones claras
‚Ä¢ Enf√≥cate en lo M√ÅS RELEVANTE, no en todo
‚Ä¢ Usa emojis para hacer m√°s visual la informaci√≥n

FORMATO REQUERIDO:
## üìä An√°lisis de [TEMA]

**üîç B√∫squeda realizada:** [explicar brevemente qu√© se busc√≥]

### üìà Hallazgos principales:
‚Ä¢ [m√°ximo 3 puntos clave]
‚Ä¢ [usar bullets para f√°cil lectura]
‚Ä¢ [incluir datos espec√≠ficos si son relevantes]

### üí≠ Sentimiento general:
[describir en 1-2 l√≠neas el sentimiento predominante]

### ‚ö° Insights clave:
[m√°ximo 2 insights importantes]

### üéØ Conclusi√≥n:
[resumen en 1-2 l√≠neas]

REGLAS IMPORTANTES:
- NO incluyas todos los tweets encontrados
- NO repitas informaci√≥n del prompt de b√∫squeda 
- S√ç menciona los n√∫meros m√°s relevantes (ej: "En 15 tweets analizados...")
- S√ç incluye hashtags o t√©rminos trending si son relevantes
- ENF√ìCATE en el valor para el usuario, no en el proceso t√©cnico

Datos obtenidos: ${JSON.stringify(toolResult, null, 2)}`
          },
          {
            role: 'user',
            content: message
          }
        ],
        temperature: 0.3, // M√°s determin√≠stico para formato consistente
        max_tokens: 600   // Limitar longitud de respuesta
      });

      const finalResponse = finalCompletion.choices[0].message.content;

      // Formatear respuesta para mejor experiencia de usuario
      const formattedResponse = formatChatResponse(finalResponse, toolResult);

      // 6. Guardar respuesta del asistente en memories
      await memoriesService.saveMessage({
        sessionId: chatSessionId,
        userId: userId,
        role: 'assistant',
        content: formattedResponse,
        messageType: 'message',
        tokensUsed: (completion.usage?.total_tokens || 0) + (finalCompletion.usage?.total_tokens || 0),
        modelUsed: 'gpt-4o-mini',
        toolsUsed: [functionName],
        contextSources: toolResult.tweets ? ['twitter'] : [],
        metadata: { 
          requestId: requestId,
          toolArgs: functionArgs,
          executionTime: executionTime,
          toolResult: toolResult.success ? 'success' : 'error',
          responseFormatted: true, // Indicar que se aplic√≥ formato
          generatedTitle: generatedTitle,
          detectedGroup: detectedGroup
        }
      });

      res.json({
        success: true,
        response: formattedResponse,
        toolUsed: functionName,
        toolArgs: functionArgs,
        toolResult: toolResult,
        sessionId: chatSessionId,
        requestId: requestId,
        executionTime: executionTime,
        timestamp: new Date().toISOString(),
        responseMetadata: {
          originalLength: finalResponse.length,
          formattedLength: formattedResponse.length,
          formatApplied: true,
          tweetsAnalyzed: toolResult.tweets_found || 0
        }
      });

    } else {
      // 5. Respuesta directa sin usar herramientas
      const directResponse = assistantMessage.content;
      
      // Formatear respuesta directa tambi√©n
      const formattedDirectResponse = formatChatResponse(directResponse);

      // Guardar respuesta del asistente en memories
      await memoriesService.saveMessage({
        sessionId: chatSessionId,
        userId: userId,
        role: 'assistant',
        content: formattedDirectResponse,
        messageType: 'message',
        tokensUsed: completion.usage?.total_tokens || 0,
        modelUsed: 'gpt-4o-mini',
        toolsUsed: [],
        contextSources: [],
        metadata: { 
          requestId: requestId,
          responseType: 'direct',
          responseFormatted: true
        }
      });

      res.json({
        success: true,
        response: formattedDirectResponse,
        toolUsed: null,
        sessionId: chatSessionId,
        requestId: requestId,
        timestamp: new Date().toISOString(),
        responseMetadata: {
          originalLength: directResponse.length,
          formattedLength: formattedDirectResponse.length,
          formatApplied: true,
          responseType: 'direct'
        }
      });
    }

  } catch (error) {
    console.error('‚ùå Error en consulta Vizta Chat:', error);
    res.status(500).json({
      success: false,
      message: 'Error procesando consulta',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/scrapes
 * Obtener scrapes del usuario
 */
router.get('/scrapes', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const { limit, offset, herramienta, categoria, sessionId } = req.query;

    const scrapes = await recentScrapesService.getUserScrapes(userId, {
      limit: parseInt(limit) || 20,
      offset: parseInt(offset) || 0,
      herramienta,
      categoria,
      sessionId
    });

    res.json({
      success: true,
      scrapes: scrapes,
      count: scrapes.length
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo scrapes:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo scrapes',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/stats
 * Obtener estad√≠sticas de scrapes del usuario
 */
router.get('/stats', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const stats = await recentScrapesService.getUserScrapeStats(userId);

    res.json({
      success: true,
      stats: stats
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo estad√≠sticas:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo estad√≠sticas',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/session/:sessionId
 * Obtener scrapes de una sesi√≥n espec√≠fica
 */
router.get('/session/:sessionId', verifyUserAccess, async (req, res) => {
  try {
    const { sessionId } = req.params;
    const scrapes = await recentScrapesService.getSessionScrapes(sessionId);

    res.json({
      success: true,
      scrapes: scrapes,
      sessionId: sessionId,
      count: scrapes.length
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo scrapes de sesi√≥n:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo scrapes de sesi√≥n',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/tools
 * Obtener herramientas MCP disponibles
 */
router.get('/tools', verifyUserAccess, async (req, res) => {
  try {
    const tools = await mcpService.listAvailableTools();

    res.json({
      success: true,
      tools: tools,
      count: tools.length
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo herramientas MCP:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo herramientas',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/conversations
 * Obtener lista de conversaciones del usuario
 */
router.get('/conversations', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const { limit } = req.query;

    const sessions = await memoriesService.getUserSessions(userId, parseInt(limit) || 20);

    res.json({
      success: true,
      conversations: sessions,
      count: sessions.length
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo conversaciones:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo conversaciones',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/conversation/:sessionId
 * Obtener mensajes de una conversaci√≥n espec√≠fica
 */
router.get('/conversation/:sessionId', verifyUserAccess, async (req, res) => {
  try {
    const { sessionId } = req.params;
    const { limit } = req.query;

    const messages = await memoriesService.getSessionMessages(sessionId, parseInt(limit) || 50);

    res.json({
      success: true,
      messages: messages,
      sessionId: sessionId,
      count: messages.length
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo mensajes de conversaci√≥n:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo mensajes de conversaci√≥n',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/memory-stats
 * Obtener estad√≠sticas de uso de memoria del usuario
 */
router.get('/memory-stats', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const stats = await memoriesService.getUserMemoryStats(userId);

    res.json({
      success: true,
      stats: stats
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo estad√≠sticas de memoria:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo estad√≠sticas de memoria',
      error: error.message
    });
  }
});

/**
 * DELETE /api/vizta-chat/conversation/:sessionId
 * Eliminar una conversaci√≥n completa
 */
router.delete('/conversation/:sessionId', verifyUserAccess, async (req, res) => {
  try {
    const { sessionId } = req.params;
    const userId = req.user.id;

    // Verificar que la sesi√≥n pertenece al usuario
    const messages = await memoriesService.getSessionMessages(sessionId, 1);
    if (messages.length === 0 || messages[0].user_id !== userId) {
      return res.status(404).json({
        success: false,
        message: 'Conversaci√≥n no encontrada'
      });
    }

    // Eliminar todos los mensajes de la sesi√≥n
    const { error } = await supabase
      .from('memories')
      .delete()
      .eq('session_id', sessionId)
      .eq('user_id', userId);

    if (error) {
      throw error;
    }

    res.json({
      success: true,
      message: 'Conversaci√≥n eliminada exitosamente',
      sessionId: sessionId
    });

  } catch (error) {
    console.error('‚ùå Error eliminando conversaci√≥n:', error);
    res.status(500).json({
      success: false,
      message: 'Error eliminando conversaci√≥n',
      error: error.message
    });
  }
});

/**
 * POST /api/vizta-chat/test-expansion
 * Endpoint de prueba para probar la expansi√≥n inteligente de t√©rminos
 */
router.post('/test-expansion', verifyUserAccess, async (req, res) => {
  try {
    const { query } = req.body;
    
    if (!query || typeof query !== 'string' || query.trim().length === 0) {
      return res.status(400).json({
        success: false,
        message: 'El par√°metro "query" es requerido y debe ser un string no vac√≠o'
      });
    }

    // Obtener herramientas disponibles del MCP
    const availableTools = await mcpService.listAvailableTools();
    
    // Simular el proceso de expansi√≥n que har√≠a GPT-4o mini
    const originalQuery = query.trim();
    
    // Usar las funciones de expansi√≥n del MCP para mostrar c√≥mo funcionar√≠an
    console.log(`üß™ Prueba de expansi√≥n para: "${originalQuery}"`);
    
    // Crear un prompt de ejemplo mostrando c√≥mo GPT-4o mini deber√≠a procesar
    const examplePrompt = `USUARIO: "${originalQuery}"

AN√ÅLISIS ESTRAT√âGICO:
1. T√©rminos detectados: ${originalQuery.toLowerCase().split(' ').join(', ')}
2. Contexto inferido: Guatemala, redes sociales
3. Tipo de consulta: ${originalQuery.toLowerCase().includes('sentimiento') || originalQuery.toLowerCase().includes('opinion') ? 'An√°lisis de sentimiento' : 'B√∫squeda de contenido'}

EXPANSI√ìN SUGERIDA:
- Original: "${originalQuery}"
- Expandido: [Se simular√≠a la expansi√≥n aqu√≠]
- Hashtags probables: #Guatemala, #GuatemalaGt
- T√©rminos relacionados: [Se agregar√≠an t√©rminos espec√≠ficos]
- L√≠mite recomendado: ${originalQuery.toLowerCase().includes('sentimiento') ? '20-25 tweets' : '15 tweets'}

HERRAMIENTAS A USAR:
- nitter_context con par√°metros optimizados
- location: guatemala
- limit: optimizado seg√∫n tipo de consulta`;

    res.json({
      success: true,
      test_results: {
        original_query: originalQuery,
        analysis_type: originalQuery.toLowerCase().includes('sentimiento') || originalQuery.toLowerCase().includes('opinion') ? 'sentiment_analysis' : 'content_search',
        suggested_improvements: {
          should_expand_terms: true,
          should_include_hashtags: true,
          should_add_guatemalan_context: true,
          recommended_limit: originalQuery.toLowerCase().includes('sentimiento') ? 20 : 15
        },
        example_prompt: examplePrompt,
        available_tools: availableTools.map(tool => ({
          name: tool.name,
          description: tool.description,
          optimizations_applied: tool.name === 'nitter_context' ? [
            'Expansi√≥n inteligente de t√©rminos',
            'Optimizaci√≥n autom√°tica de l√≠mites',
            'Contexto guatemalteco a√±adido',
            'An√°lisis de sentimiento incluido'
          ] : []
        }))
      },
      instructions: {
        next_steps: [
          'El sistema ahora expandir√° autom√°ticamente los t√©rminos de b√∫squeda',
          'GPT-4o mini usar√° estrategias inteligentes en lugar de t√©rminos literales',
          'Los l√≠mites se optimizar√°n seg√∫n el tipo de an√°lisis',
          'Se incluir√° contexto guatemalteco autom√°ticamente'
        ],
        example_expansions: {
          'marcha del orgullo': 'Orgullo2025 OR MarchadelOrgullo OR OrguIIoGt OR Pride OR LGBTI OR diversidad',
          'elecciones': 'EleccionesGt OR TSE OR voto OR candidatos OR Elecciones2025 OR procesoelectoral',
          'presidente': 'BernardoArevalo OR presidente OR GobiernoGt OR CasaPresidencial OR Presidencia'
        }
      }
    });

  } catch (error) {
    console.error('‚ùå Error en test de expansi√≥n:', error);
    res.status(500).json({
      success: false,
      message: 'Error probando expansi√≥n de t√©rminos',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/scrapes/grouped
 * Obtener scrapes agrupados inteligentemente
 */
router.get('/scrapes/grouped', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const { limit, offset, detectedGroup, categoria } = req.query;

    const groupedScrapes = await recentScrapesService.getGroupedScrapes(userId, {
      limit: parseInt(limit) || 20,
      offset: parseInt(offset) || 0,
      detectedGroup,
      categoria
    });

    res.json({
      success: true,
      groups: groupedScrapes,
      count: groupedScrapes.length,
      metadata: {
        totalGroups: groupedScrapes.length,
        requestedAt: new Date().toISOString()
      }
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo scrapes agrupados:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo scrapes agrupados',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/scrapes/grouped-stats
 * Obtener estad√≠sticas de agrupaci√≥n
 */
router.get('/scrapes/grouped-stats', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const stats = await recentScrapesService.getGroupedStats(userId);

    res.json({
      success: true,
      stats: stats,
      generatedAt: new Date().toISOString()
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo estad√≠sticas agrupadas:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo estad√≠sticas agrupadas',
      error: error.message
    });
  }
});

module.exports = router; 