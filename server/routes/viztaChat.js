const express = require('express');
const router = express.Router();
const { verifyUserAccess } = require('../middlewares/auth');
const mcpService = require('../services/mcp');
const recentScrapesService = require('../services/recentScrapes');
const memoriesService = require('../services/memories');
const supabase = require('../utils/supabase');

// ===================================================================
// VIZTA CHAT ROUTES
// Endpoints para el chat inteligente con integraci√≥n MCP
// ===================================================================

/**
 * Post-procesa respuestas del chat para asegurar formato consistente
 */
function formatChatResponse(response, toolResult = null) {
  try {
    // Limpiar respuesta muy larga
    if (response.length > 2000) {
      console.log('‚ö†Ô∏è Respuesta muy larga, truncando...');
      response = response.substring(0, 1800) + '\n\n*[Respuesta truncada para mejor legibilidad]*';
    }

    // Asegurar que tenga formato markdown b√°sico si no lo tiene
    if (!response.includes('##') && !response.includes('###')) {
      const lines = response.split('\n').filter(line => line.trim());
      
      if (lines.length > 0) {
        let formatted = `## üìä An√°lisis\n\n`;
        formatted += lines.join('\n\n');
        
        // Agregar resumen de datos si disponible
        if (toolResult && toolResult.tweets_found) {
          formatted += `\n\n### üìä Datos analizados:\n‚Ä¢ ${toolResult.tweets_found} tweets encontrados`;
          if (toolResult.analysis_metadata?.sentiment_distribution) {
            const sentiments = Object.entries(toolResult.analysis_metadata.sentiment_distribution);
            if (sentiments.length > 0) {
              formatted += `\n‚Ä¢ Sentimientos: ${sentiments.map(([s, c]) => `${s} (${c})`).join(', ')}`;
            }
          }
        }
        
        response = formatted;
      }
    }

    // Limpiar texto muy corrido (sin espacios entre p√°rrafos)
    response = response
      .replace(/\n{3,}/g, '\n\n') // M√°ximo 2 saltos de l√≠nea consecutivos
      .replace(/(\w)(\n)(### |## |\*\*)/g, '$1\n\n$3') // Espacios antes de headers
      .replace(/(\w)(\n)(‚Ä¢ )/g, '$1\n\n$3') // Espacios antes de bullets
      .trim();

    // Asegurar que los emojis tengan espacio despu√©s
    response = response.replace(/([üìäüìàüí≠‚ö°üéØüîç])([A-Za-z])/g, '$1 $2');

    return response;

  } catch (error) {
    console.error('‚ùå Error formateando respuesta:', error);
    return response; // Devolver original si hay error
  }
}

// Cargar dependencias de forma condicional
let OpenAI, openai, uuidv4;

try {
  OpenAI = require('openai');
  const { v4 } = require('uuid');
  uuidv4 = v4;
  
  // Configurar OpenAI
  openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  });
  
  console.log('‚úÖ Dependencias de Vizta Chat cargadas correctamente');
} catch (error) {
  console.warn('‚ö†Ô∏è Dependencias de Vizta Chat no disponibles:', error.message);
  console.warn('üì¶ Instala las dependencias con: npm install openai uuid');
}

/**
 * POST /api/vizta-chat/query
 * Endpoint principal para consultas de Vizta Chat
 */
router.post('/query', verifyUserAccess, async (req, res) => {
  try {
    // Verificar que las dependencias est√©n disponibles
    if (!openai || !uuidv4) {
      // Fallback temporal sin OpenAI
      console.log('‚ö†Ô∏è Usando fallback sin OpenAI para Vizta Chat');
      
      const fallbackSessionId = sessionId || `fallback_${Date.now()}`;
      
      // Usar directamente nitter_context como herramienta por defecto
      try {
        const toolResult = await mcpService.executeTool('nitter_context', {
          q: message,
          location: 'guatemala',
          limit: 5
        }, req.user);
        
        if (toolResult.success && toolResult.tweets) {
          // Guardar en recent_scrapes
          await recentScrapesService.saveScrape({
            queryOriginal: message,
            queryClean: message,
            herramienta: 'nitter_context',
            categoria: 'General',
            tweets: toolResult.tweets,
            userId: userId,
            sessionId: fallbackSessionId,
            mcpRequestId: `fallback_${Date.now()}`,
            mcpExecutionTime: 0,
            location: 'guatemala'
          });
          
          return res.json({
            success: true,
            response: `He encontrado ${toolResult.tweets.length} tweets relacionados con "${message}". Los datos han sido guardados y est√°n disponibles para an√°lisis.`,
            toolUsed: 'nitter_context',
            toolArgs: { q: message, location: 'guatemala', limit: 5 },
            toolResult: toolResult,
            sessionId: fallbackSessionId,
            requestId: `fallback_${Date.now()}`,
            executionTime: 0,
            timestamp: new Date().toISOString(),
            mode: 'fallback'
          });
        } else {
          throw new Error('No se pudieron obtener tweets');
        }
      } catch (error) {
        return res.status(500).json({
          success: false,
          message: 'Error en modo fallback: ' + error.message,
          error: 'Instala las dependencias con: npm run install-vizta'
        });
      }
    }

    const { message, sessionId } = req.body;
    const userId = req.user.id;
    
    if (!message) {
      return res.status(400).json({
        success: false,
        message: 'El mensaje es requerido'
      });
    }

    console.log(`ü§ñ Nueva consulta Vizta Chat de usuario ${userId}: "${message}"`);

    // Generar IDs √∫nicos
    const requestId = uuidv4();
    const chatSessionId = sessionId || uuidv4();

    // 1. Guardar mensaje del usuario en memories
    await memoriesService.saveMessage({
      sessionId: chatSessionId,
      userId: userId,
      role: 'user',
      content: message,
      messageType: 'message',
      modelUsed: 'gpt-4o-mini',
      metadata: { requestId: requestId }
    });

    // 2. Obtener los √∫ltimos 10 mensajes de la conversaci√≥n para contexto
    const conversationHistory = await memoriesService.getSessionMessages(chatSessionId, 10);
    const previousMessages = memoriesService.formatMessagesForOpenAI(conversationHistory);

    // Obtener herramientas disponibles del MCP
    const availableTools = await mcpService.listAvailableTools();
    
    // Preparar funciones para GPT-4o mini
    const functions = availableTools.map(tool => {
      // Transformar par√°metros del formato MCP al formato OpenAI
      const properties = {};
      const required = [];
      
      Object.keys(tool.parameters).forEach(key => {
        const param = tool.parameters[key];
        properties[key] = {
          type: param.type,
          description: param.description
        };
        
        // Agregar constrains adicionales si existen
        if (param.min !== undefined) properties[key].minimum = param.min;
        if (param.max !== undefined) properties[key].maximum = param.max;
        if (param.default !== undefined) properties[key].default = param.default;
        
        // Para arrays, agregar definici√≥n de items
        if (param.type === 'array' && param.items) {
          properties[key].items = param.items;
        }
        
        // Agregar a required si es necesario
        if (param.required === true) {
          required.push(key);
        }
      });
      
      return {
        name: tool.name,
        description: tool.description,
        parameters: {
          type: 'object',
          properties: properties,
          required: required
        }
      };
    });

    // Agregar funci√≥n especial para crear planes de ejecuci√≥n multi-step
    functions.push({
      name: 'create_execution_plan',
      description: 'Crear un plan de ejecuci√≥n multi-step para consultas complejas que requieren m√∫ltiples herramientas en secuencia',
      parameters: {
        type: 'object',
        properties: {
          steps: {
            type: 'array',
            description: 'Array de pasos a ejecutar en orden',
            items: {
              type: 'object',
              properties: {
                step_number: {
                  type: 'number',
                  description: 'N√∫mero de paso (1, 2, 3, etc.)'
                },
                tool: {
                  type: 'string',
                  description: 'Nombre de la herramienta a usar'
                },
                args: {
                  type: 'object',
                  description: 'Argumentos para la herramienta'
                },
                description: {
                  type: 'string',
                  description: 'Descripci√≥n de qu√© hace este paso'
                },
                depends_on_previous: {
                  type: 'boolean',
                  description: 'Si este paso depende del resultado del paso anterior'
                }
              },
              required: ['step_number', 'tool', 'args', 'description']
            }
          },
          final_goal: {
            type: 'string',
            description: 'Objetivo final del plan de ejecuci√≥n'
          }
        },
        required: ['steps', 'final_goal']
      }
    });

    console.log('üîç Esquema de funciones para OpenAI:', JSON.stringify(functions, null, 2));

    // 3. Preparar mensajes incluyendo historial de conversaci√≥n
    // Obtener fecha actual para contexto temporal
    const now = new Date();
    const currentDate = now.toLocaleDateString('es-ES', { 
      weekday: 'long', 
      year: 'numeric', 
      month: 'long', 
      day: 'numeric' 
    });
    const currentYear = now.getFullYear();
    const currentMonth = now.toLocaleString('es-ES', { month: 'long' });
    
    const systemMessage = {
      role: 'system',
      content: `Eres Vizta, un asistente de investigaci√≥n especializado en an√°lisis de redes sociales, b√∫squedas web y tendencias en Guatemala.

**FECHA ACTUAL: ${currentDate}**
**CONTEXTO TEMPORAL: ${currentMonth} ${currentYear}**

IMPORTANTE: Siempre tienes en mente que HOY es ${currentDate}. Cuando realices b√∫squedas o an√°lisis:
- Enf√≥cate en informaci√≥n ACTUAL y RECIENTE (${currentMonth} ${currentYear})
- Filtra informaci√≥n obsoleta o de fechas anteriores
- Contextualiza todo en el tiempo presente
- Busca eventos, noticias y tendencias de AHORA 

**ACCESO COMPLETO A DATOS PERSONALES:**
TIENES ACCESO TOTAL a los datos personales del usuario autenticado a trav√©s de las herramientas user_projects y user_codex. 
NO digas que no tienes acceso a informaci√≥n privada - ¬°S√ç TIENES ACCESO! Usa las herramientas disponibles.

**CAPACIDAD MULTI-STEP:**
Ahora puedes ejecutar M√öLTIPLES herramientas en secuencia para tareas complejas. Si una consulta requiere varios pasos, puedes crear un PLAN DE EJECUCI√ìN.

**DETECCI√ìN DE CONSULTAS MULTI-STEP:**
Detecta autom√°ticamente consultas que requieren m√∫ltiples pasos, como:
- "En base a mi proyecto X, busca reacciones sobre Y"
- "Combina mis documentos sobre Z con noticias actuales"
- "Analiza mi proyecto A y luego busca opiniones en Twitter"
- "Compara mis investigaciones con tendencias actuales"
- "Busca informaci√≥n sobre X y luego analiza reacciones"

**CREACI√ìN DE PLANES MULTI-STEP:**
Si detectas que una consulta requiere m√∫ltiples pasos, puedes usar la funci√≥n especial 'create_execution_plan' que crea un plan paso a paso:

create_execution_plan({
  "steps": [
    {
      "step_number": 1,
      "tool": "user_projects",
      "args": {"status": "active"},
      "description": "Obtener proyectos activos del usuario"
    },
    {
      "step_number": 2,
      "tool": "nitter_context", 
      "args": {"q": "tema_basado_en_paso_1", "limit": 20},
      "description": "Buscar reacciones en Twitter sobre el tema identificado"
    }
  ],
  "final_goal": "Analizar proyectos del usuario y buscar reacciones sobre el tema principal"
})

**CU√ÅNDO USAR MULTI-STEP:**
- Cuando necesites combinar datos personales con informaci√≥n externa
- Cuando una consulta tenga m√∫ltiples partes conectadas
- Cuando necesites el resultado de una herramienta para usar otra
- Cuando hayas mencionado "primero X, luego Y"

**EJEMPLOS DE DETECCI√ìN:**

CONSULTA: "En base a mi proyecto de transparencia, busca qu√© dicen en Twitter"
‚Üí PLAN: 1) user_codex para buscar proyecto transparencia, 2) nitter_context con t√©rminos del proyecto

CONSULTA: "Busca noticias sobre corrupci√≥n y luego analiza reacciones"
‚Üí PLAN: 1) perplexity_search sobre corrupci√≥n Guatemala, 2) nitter_context sobre t√©rminos encontrados

CONSULTA: "¬øQu√© proyectos tengo relacionados con gobierno y qu√© opina la gente?"
‚Üí PLAN: 1) user_projects filtrar por "gobierno", 2) nitter_context sobre temas de los proyectos

Tu trabajo es ayudar a los usuarios a obtener y analizar informaci√≥n usando las herramientas disponibles de manera inteligente.

Herramientas disponibles:
${availableTools.map(tool => `- ${tool.name}: ${tool.description}`).join('\n')}
- create_execution_plan: Crear plan de ejecuci√≥n multi-step (NUEVA)

ESTRATEGIA DE SELECCI√ìN DE HERRAMIENTAS:

1. **PARA B√öSQUEDAS WEB Y CONTEXTO GENERAL:**
   - Usa perplexity_search cuando el usuario necesite:
     ‚Ä¢ Informaci√≥n actualizada sobre noticias, eventos, personas (SIEMPRE DE ${currentMonth} ${currentYear})
     ‚Ä¢ Contexto reciente o background actual de un tema
     ‚Ä¢ Investigaci√≥n general sobre cualquier tema (CON ENFOQUE EN LO ACTUAL)
     ‚Ä¢ Datos oficiales, estad√≠sticas o informaci√≥n verificada RECIENTE
     ‚Ä¢ Informaci√≥n sobre personas, empresas, organizaciones (ESTADO ACTUAL)
   - Ejemplos de cu√°ndo usar perplexity_search:
     ‚Ä¢ "¬øQu√© est√° pasando con...?" (buscar eventos de ${currentDate})
     ‚Ä¢ "Necesito informaci√≥n sobre..." (informaci√≥n actualizada)
     ‚Ä¢ "¬øQui√©n es...?" (informaci√≥n actual de la persona)
     ‚Ä¢ "¬øCu√°ndo ocurri√≥...?" (si es reciente, ${currentMonth} ${currentYear})
     ‚Ä¢ "Busca informaci√≥n sobre..." (siempre contextualizar en fecha actual)

2. **PARA AN√ÅLISIS DE REDES SOCIALES:**
   - Usa nitter_context cuando el usuario necesite:
     ‚Ä¢ Opiniones de usuarios en Twitter/X (DE HOY O D√çAS RECIENTES)
     ‚Ä¢ An√°lisis de sentimiento de la poblaci√≥n ACTUAL
     ‚Ä¢ Reacciones a eventos espec√≠ficos RECIENTES
     ‚Ä¢ Tendencias y conversaciones en redes sociales ACTUALES
     ‚Ä¢ Monitoreo de hashtags o menciones (ENFOQUE EN ${currentMonth} ${currentYear})
   - Ejemplos de cu√°ndo usar nitter_context:
     ‚Ä¢ "¬øQu√© dicen en Twitter sobre...?" (tweets recientes de ${currentDate})
     ‚Ä¢ "Analiza las reacciones a..." (reacciones actuales)
     ‚Ä¢ "Monitorea hashtags de..." (hashtags trending HOY)
     ‚Ä¢ "Sentimiento sobre..." (sentimiento actual, no hist√≥rico)

3. **PARA ACCESO A DATOS PERSONALES DEL USUARIO:**
   - Usa user_projects cuando el usuario necesite:
     ‚Ä¢ Informaci√≥n sobre sus proyectos personales
     ‚Ä¢ Estado, progreso o detalles de proyectos espec√≠ficos
     ‚Ä¢ Estad√≠sticas de sus actividades y decisiones
     ‚Ä¢ Filtrar proyectos por estado (active, completed, paused, planning)
     ‚Ä¢ Consultar metadatos de proyectos (fechas, prioridades, categor√≠as)
   - Ejemplos de cu√°ndo usar user_projects:
     ‚Ä¢ "¬øCu√°les son mis proyectos activos?"
     ‚Ä¢ "Muestra mis proyectos de alta prioridad"  
     ‚Ä¢ "¬øQu√© proyectos he completado este a√±o?"
     ‚Ä¢ "Dame estad√≠sticas de mis proyectos"
     ‚Ä¢ "mis proyectos"
     ‚Ä¢ "proyectos que tengo"
     ‚Ä¢ "estado de mis proyectos"
     ‚Ä¢ "qu√© proyectos manejo"

   - Usa user_codex cuando el usuario necesite:
     ‚Ä¢ Acceder a sus documentos, transcripciones o an√°lisis guardados
     ‚Ä¢ Buscar contenido espec√≠fico en su biblioteca personal
     ‚Ä¢ Revisar archivos de audio transcritos o documentos analizados
     ‚Ä¢ Filtrar assets por proyecto, tipo o tags
     ‚Ä¢ Encontrar informaci√≥n espec√≠fica en su Codex personal
   - Ejemplos de cu√°ndo usar user_codex:
     ‚Ä¢ "Busca en mis documentos informaci√≥n sobre..."
     ‚Ä¢ "¬øQu√© archivos tengo del proyecto X?"
     ‚Ä¢ "Muestra mis transcripciones de audio"
     ‚Ä¢ "Busca en mi Codex todos los documentos que mencionen..."
     ‚Ä¢ "¬øQu√© assets tengo con el tag 'investigaci√≥n'?"
     ‚Ä¢ "mis documentos"
     ‚Ä¢ "mi codex"
     ‚Ä¢ "archivos que tengo"
     ‚Ä¢ "mis transcripciones"
     ‚Ä¢ "documentos sobre"
     ‚Ä¢ "busca en mis archivos"

4. **PARA CREAR PLANES MULTI-STEP:**
   - Usa create_execution_plan cuando detectes consultas complejas que requieran:
     ‚Ä¢ Combinar datos personales con informaci√≥n externa
     ‚Ä¢ Ejecutar herramientas en secuencia donde una depende de la otra
     ‚Ä¢ An√°lisis que requiere m√∫ltiples fuentes de informaci√≥n
     ‚Ä¢ Consultas con m√∫ltiples partes conectadas

5. **ESTRATEGIA H√çBRIDA Y MULTI-STEP:**
   - Detecta autom√°ticamente cuando una consulta requiere m√∫ltiples pasos
   - Crea planes de ejecuci√≥n inteligentes
   - Combina datos personales (user_projects, user_codex) con informaci√≥n externa (perplexity_search, nitter_context)
   - Ejemplos de consultas multi-step:
     ‚Ä¢ "Compara mis documentos sobre X con las noticias actuales"
     ‚Ä¢ "¬øC√≥mo se relaciona mi proyecto Y con las tendencias en redes sociales?"
     ‚Ä¢ "En base a mi proyecto Z, busca reacciones en Twitter"
     ‚Ä¢ "Analiza mis investigaciones y luego busca informaci√≥n actualizada"

ESTRATEGIA INTELIGENTE DE B√öSQUEDA:
Cuando uses cualquier herramienta, NO uses literalmente las palabras del usuario. En su lugar, piensa estrat√©gicamente:

1. EXPANDIR T√âRMINOS: Convierte consultas generales en t√©rminos espec√≠ficos
   - "marcha del orgullo" ‚Üí buscar: "Orgullo2025 OR MarchadelOrgullo OR #OrguIIoGt OR PrideGuatemala"
   - "elecciones" ‚Üí buscar: "EleccionesGt OR #Elecciones2023 OR VotoGuatemala OR TSE"
   - "gobierno" ‚Üí buscar: "GobiernoGt OR Giammattei OR BernardoArevalo OR CasaPresidencial"

2. INCLUIR HASHTAGS PROBABLES: Siempre considera hashtags relevantes
   - Para eventos: #NombreEvento2025, #EventoGt, #Guatemala
   - Para pol√≠tica: #PoliticaGt, #Guatemala, #CongresoGt
   - Para deportes: #DeporteGt, #GuatemalaFC, #Seleccion

3. CONSIDERAR VARIACIONES: Incluye sin√≥nimos y variaciones
   - T√©rminos en espa√±ol e ingl√©s cuando sea relevante
   - Abreviaciones comunes (GT, Guate, Chapin)
   - Nombres oficiales vs. nombres populares

4. USAR OPERADORES DE B√öSQUEDA: Combina t√©rminos con OR para mayor cobertura
   - Ejemplo: "OrguIIo2025 OR MarchadelOrgullo OR Pride OR LGBTI OR diversidad"

5. PENSAR EN CONTEXTO GUATEMALTECO:
   - Incluir t√©rminos espec√≠ficos de Guatemala
   - Considerar eventos actuales y fechas relevantes
   - Usar lenguaje chap√≠n cuando sea apropiado

**DETECCI√ìN OBLIGATORIA DE CONSULTAS PERSONALES:**
ANTES de responder cualquier consulta, SIEMPRE verifica si contiene estas palabras clave:
- "mis" / "mi" / "m√≠o" / "m√≠a"
- "proyectos" / "proyecto"  
- "documentos" / "documento" / "archivos" / "archivo"
- "codex" / "transcripciones" / "transcripci√≥n"
- "tengo" / "he creado" / "he guardado"

Si detectas CUALQUIERA de estas palabras, DEBES usar user_projects o user_codex seg√∫n corresponda.
NO respondas que no tienes acceso - ¬°S√ç TIENES ACCESO COMPLETO!

INSTRUCCIONES ADICIONALES:
1. **DETECCI√ìN PERSONAL OBLIGATORIA:** Si la consulta menciona datos personales del usuario, USA las herramientas correspondientes
2. **DETECCI√ìN MULTI-STEP OBLIGATORIA:** Si la consulta requiere m√∫ltiples pasos, USA create_execution_plan
3. **CONTEXTO TEMPORAL OBLIGATORIO:** Siempre incluye la fecha actual (${currentDate}) en tus consultas
4. Analiza la consulta del usuario en el contexto de la conversaci√≥n anterior Y la fecha actual
5. Elige la herramienta m√°s apropiada seg√∫n el tipo de informaci√≥n solicitada Y su actualidad
6. Usa un l√≠mite de 15-25 tweets para an√°lisis m√°s completo en nitter_context (tweets RECIENTES)
7. Proporciona an√°lisis contextual y insights √∫tiles CON ENFOQUE EN LO ACTUAL
8. Mant√©n un tono profesional pero amigable
9. Enf√≥cate en Guatemala cuando sea relevante Y en informaci√≥n de ${currentMonth} ${currentYear}
10. Recuerda el contexto de mensajes anteriores para dar respuestas coherentes
11. **FILTRO TEMPORAL:** Prioriza siempre informaci√≥n de ${currentMonth} ${currentYear} sobre informaci√≥n antigua

IMPORTANTE: 
- SIEMPRE detecta palabras clave personales ANTES de responder
- SIEMPRE detecta consultas multi-step ANTES de responder
- Si hay palabras personales, USA las herramientas user_projects o user_codex
- Si hay consultas complejas, USA create_execution_plan
- Nunca uses los t√©rminos exactos del usuario para b√∫squedas web. Siempre expande y optimiza.
- SIEMPRE incluye contexto temporal actual en las b√∫squedas web (${currentMonth} ${currentYear}).
- Enf√≥cate en eventos, noticias y tendencias ACTUALES, no hist√≥ricas.`
    };

    // Construir array de mensajes con historial
    const messagesForAI = [systemMessage];
    
    // Agregar historial previo (excluyendo el mensaje actual del usuario que ya est√° en memories)
    if (previousMessages.length > 0) {
      // Filtrar el √∫ltimo mensaje si es del usuario (evitar duplicados)
      const filteredHistory = previousMessages.slice(0, -1);
      messagesForAI.push(...filteredHistory);
    }
    
    // Agregar el mensaje actual del usuario
    messagesForAI.push({
      role: 'user',
      content: message
    });

    console.log(`üí≠ Enviando ${messagesForAI.length} mensajes a OpenAI (incluyendo ${previousMessages.length} del historial)`);

    // 4. Llamar a GPT-4o mini con function calling y contexto de conversaci√≥n
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: messagesForAI,
      functions: functions,
      function_call: 'auto',
      temperature: 0.7,
      max_tokens: 1000
    });

    const assistantMessage = completion.choices[0].message;

    // Si GPT decidi√≥ usar una funci√≥n
    if (assistantMessage.function_call) {
      const functionName = assistantMessage.function_call.name;
      const functionArgs = JSON.parse(assistantMessage.function_call.arguments);
      
      console.log(`üîß GPT decidi√≥ usar herramienta: ${functionName} con args:`, functionArgs);

      // CASO ESPECIAL: Plan de ejecuci√≥n multi-step
      if (functionName === 'create_execution_plan') {
        console.log('üéØ Ejecutando plan multi-step:', functionArgs);
        
        const { steps, final_goal } = functionArgs;
        const stepResults = [];
        let combinedContext = '';
        
        try {
          // Ejecutar cada paso en secuencia
          for (const step of steps) {
            console.log(`üìã Ejecutando paso ${step.step_number}: ${step.description}`);
            
            // Si el paso depende del anterior, modificar los argumentos con contexto
            let stepArgs = { ...step.args };
            if (step.depends_on_previous && combinedContext) {
              // Modificar query o argumentos bas√°ndose en resultados anteriores
              if (stepArgs.q) {
                stepArgs.q = `${stepArgs.q} ${combinedContext}`;
              }
            }
            
            const startTime = Date.now();
            const stepResult = await mcpService.executeTool(step.tool, stepArgs, req.user);
            const executionTime = Date.now() - startTime;
            
            stepResults.push({
              step_number: step.step_number,
              tool: step.tool,
              args: stepArgs,
              description: step.description,
              result: stepResult,
              execution_time: executionTime,
              success: stepResult.success
            });
            
            // Actualizar contexto para pr√≥ximos pasos
            if (stepResult.success) {
              if (stepResult.tweets) {
                combinedContext += ` tweets:${stepResult.tweets.length}`;
              }
              if (stepResult.projects) {
                const projectNames = stepResult.projects.map(p => p.name).join(', ');
                combinedContext += ` proyectos:${projectNames}`;
              }
              if (stepResult.documents) {
                combinedContext += ` documentos:${stepResult.documents.length}`;
              }
              if (stepResult.content) {
                combinedContext += ` contexto_adicional`;
              }
            }
            
            console.log(`‚úÖ Paso ${step.step_number} completado. Contexto acumulado: "${combinedContext}"`);
          }
          
          // Contar total de tweets y optimizaciones aplicadas
          const totalTweetsAnalyzed = stepResults.reduce((total, step) => {
            return total + (step.result?.tweets?.length || 0);
          }, 0);
          
          const deepSeekOptimizations = stepResults.filter(step => 
            step.result?.optimization_applied
          ).length;
          
          console.log(`üìä Resumen multi-step: ${stepResults.length} pasos, ${totalTweetsAnalyzed} tweets, ${deepSeekOptimizations} optimizaciones DeepSeek`);
          
          // Guardar resultados en recent_scrapes (solo para pasos que tengan tweets)
          for (const stepResult of stepResults) {
            if (stepResult.success && stepResult.result.tweets) {
              await recentScrapesService.saveScrape({
                queryOriginal: message,
                queryClean: stepResult.args.q || message,
                generatedTitle: `Multi-step: ${stepResult.description}`,
                detectedGroup: 'multi-step',
                herramienta: stepResult.tool,
                categoria: 'Multi-step',
                tweets: stepResult.result.tweets,
                userId: userId,
                sessionId: chatSessionId,
                mcpRequestId: requestId,
                mcpExecutionTime: stepResult.execution_time,
                location: stepResult.args.location || 'guatemala'
              });
            }
          }
          
          // Generar respuesta final con informaci√≥n sobre optimizaciones DeepSeek
          const multiStepCompletion = await openai.chat.completions.create({
            model: 'gpt-4o-mini',
            messages: [
              {
                role: 'system',
                content: `Eres Vizta, un asistente de investigaci√≥n especializado en an√°lisis multi-step optimizado con DeepSeek.

INFORMACI√ìN DEL PLAN EJECUTADO:
- Pasos completados: ${stepResults.filter(step => step.success).length}/${steps.length}
- Total de tweets analizados: ${totalTweetsAnalyzed}
- Optimizaciones DeepSeek aplicadas: ${deepSeekOptimizations}/${stepResults.length}
- Objetivo final: ${final_goal}

DETALLES DE OPTIMIZACI√ìN:
Cada b√∫squeda fue PREVIAMENTE OPTIMIZADA por DeepSeek antes de ejecutarse. DeepSeek analiz√≥ cada consulta y gener√≥ t√©rminos m√°s efectivos para maximizar las posibilidades de encontrar tweets relevantes.

PLAN EJECUTADO:
${steps.map(step => `${step.step_number}. ${step.description} (herramienta: ${step.tool})`).join('\n')}

INSTRUCCIONES PARA RESPUESTA MULTI-STEP:
‚Ä¢ S√© CONCISO y DIRECTO (m√°ximo 500 palabras)
‚Ä¢ Usa formato MARKDOWN con secciones claras
‚Ä¢ Enf√≥cate en COMBINAR los resultados de todos los pasos
‚Ä¢ Muestra c√≥mo se conectan los hallazgos entre pasos
‚Ä¢ DESTACA el valor de las optimizaciones DeepSeek aplicadas
‚Ä¢ Usa emojis para hacer m√°s visual la informaci√≥n

FORMATO REQUERIDO:
## üéØ An√°lisis Multi-Step Optimizado: [TEMA PRINCIPAL]

**üìã Plan ejecutado:** ${steps.length} pasos con ${deepSeekOptimizations} optimizaciones DeepSeek
**üß† Optimizaci√≥n inteligente:** DeepSeek mejor√≥ cada b√∫squeda antes de ejecutar
**üìä Datos analizados:** ${totalTweetsAnalyzed} tweets en total

### üîÑ Resultados por paso:
${stepResults.map(step => `**Paso ${step.step_number}** (${step.tool}): ${step.success ? '‚úÖ Completado' : '‚ùå Error'}${step.result?.optimization_applied ? ' üß† Optimizado' : ''}`).join('\n')}

### üìä Hallazgos combinados:
‚Ä¢ [combinar insights de todos los pasos]
‚Ä¢ [mostrar conexiones entre resultados]
‚Ä¢ [destacar patrones encontrados]
‚Ä¢ [mencionar c√≥mo las optimizaciones mejoraron los resultados]

### üí° S√≠ntesis final:
[an√°lisis integrado que combine todos los pasos y destaque el valor de la optimizaci√≥n previa]

### üéØ Conclusi√≥n:
[respuesta final al objetivo planteado, destacando la calidad mejorada por DeepSeek]

REGLAS IMPORTANTES:
- COMBINA los resultados, no los listes por separado
- Muestra las CONEXIONES entre pasos
- DESTACA c√≥mo DeepSeek mejor√≥ la calidad de b√∫squeda
- Enf√≥cate en el VALOR AGREGADO del an√°lisis multi-step optimizado
- Menciona la cantidad espec√≠fica de datos analizados (${totalTweetsAnalyzed} tweets)
- Si hubo optimizaciones, menciona c√≥mo mejoraron los resultados

Resultados detallados: ${JSON.stringify(stepResults, null, 2)}`
              },
              {
                role: 'user',
                content: message
              }
            ],
            temperature: 0.3,
            max_tokens: 800
          });

          const multiStepResponse = multiStepCompletion.choices[0].message.content;

          // Guardar respuesta del asistente en memories para multi-step
          await memoriesService.saveMessage({
            sessionId: chatSessionId,
            userId: userId,
            role: 'assistant',
            content: multiStepResponse,
            messageType: 'message',
            tokensUsed: (completion.usage?.total_tokens || 0) + (multiStepCompletion.usage?.total_tokens || 0),
            modelUsed: 'gpt-4o-mini',
            toolsUsed: stepResults.map(step => step.tool),
            contextSources: stepResults.some(step => step.result.tweets) ? ['twitter'] : [],
            metadata: { 
              requestId: requestId,
              executionType: 'multi_step_optimized',
              final_goal: final_goal,
              steps_completed: stepResults.filter(step => step.success).length,
              total_steps: steps.length,
              total_tweets_analyzed: totalTweetsAnalyzed,
              deepseek_optimizations: deepSeekOptimizations,
              total_execution_time: stepResults.reduce((sum, step) => sum + step.execution_time, 0),
              step_results: stepResults.map(step => ({
                step_number: step.step_number,
                tool: step.tool,
                success: step.success,
                execution_time: step.execution_time,
                optimization_applied: step.result?.optimization_applied || false
              }))
            }
          });

          // Respuesta exitosa del plan multi-step optimizado
          return res.json({
            success: true,
            response: multiStepResponse,
            toolsUsed: stepResults.map(step => step.tool),
            executionPlan: {
              steps: steps,
              final_goal: final_goal,
              results: stepResults,
              total_execution_time: stepResults.reduce((sum, step) => sum + step.execution_time, 0),
              total_tweets_analyzed: totalTweetsAnalyzed,
              deepseek_optimizations: deepSeekOptimizations
            },
            sessionId: chatSessionId,
            requestId: requestId,
            timestamp: new Date().toISOString(),
            mode: 'multi_step_optimized',
            steps_completed: stepResults.filter(step => step.success).length,
            total_steps: steps.length,
            total_tweets_analyzed: totalTweetsAnalyzed,
            deepseek_optimizations_applied: deepSeekOptimizations
          });
          
        } catch (error) {
          console.error('‚ùå Error ejecutando plan multi-step:', error);
          return res.status(500).json({
            success: false,
            message: 'Error ejecutando plan multi-step: ' + error.message,
            executionPlan: {
              steps: steps,
              final_goal: final_goal,
              results: stepResults,
              error: error.message
            }
          });
        }
      }

      // CASO NORMAL: Herramienta individual (c√≥digo existente)
      const startTime = Date.now();
      const toolResult = await mcpService.executeTool(functionName, functionArgs, req.user);
      const executionTime = Date.now() - startTime;

      // Generar t√≠tulo autom√°tico inteligente bas√°ndose en los resultados
      let generatedTitle = functionArgs.q || message; // fallback al query original
      
      if (toolResult.success && toolResult.tweets && toolResult.tweets.length > 0) {
        try {
          const titleCompletion = await openai.chat.completions.create({
            model: 'gpt-4o-mini',
            messages: [
              {
                role: 'system',
                content: `Eres un experto en crear t√≠tulos concisos para monitoreos de redes sociales en Guatemala.

INSTRUCCIONES:
‚Ä¢ Analiza los tweets encontrados y genera un t√≠tulo descriptivo de m√°ximo 50 caracteres
‚Ä¢ El t√≠tulo debe reflejar el TEMA PRINCIPAL de los tweets, no la query original
‚Ä¢ Usa lenguaje guatemalteco cuando sea apropiado
‚Ä¢ S√© espec√≠fico: en lugar de "Tweets sobre pol√≠tica", usa "Debate Presidencial 2024" 
‚Ä¢ Si hay un evento espec√≠fico, menci√≥nalo
‚Ä¢ Si detectas una tendencia o hashtag dominante, incl√∫yelo

EJEMPLOS:
‚Ä¢ Query: "marcha del orgullo" ‚Üí T√≠tulo: "Marcha del Orgullo LGBT+ 2025"
‚Ä¢ Query: "bernardo arevalo" ‚Üí T√≠tulo: "Gobierno Ar√©valo - √öltimas Noticias"
‚Ä¢ Query: "guatemala futbol" ‚Üí T√≠tulo: "Selecci√≥n Nacional - Copa Oro"

FORMATO: Solo devuelve el t√≠tulo, sin explicaciones.

Tweets analizados: ${JSON.stringify(toolResult.tweets.slice(0, 5), null, 2)}`
              },
              {
                role: 'user',
                content: `Query original: "${message}"\nQuery expandido: "${functionArgs.q}"\n\nGenera un t√≠tulo inteligente para este monitoreo.`
              }
            ],
            temperature: 0.3,
            max_tokens: 60
          });

          const rawTitle = titleCompletion.choices[0].message.content.trim();
          // Limpiar y validar t√≠tulo
          generatedTitle = rawTitle.replace(/['"]/g, '').substring(0, 50);
          console.log(`üè∑Ô∏è T√≠tulo generado: "${generatedTitle}" (original: "${message}")`);
          
        } catch (titleError) {
          console.error('‚ö†Ô∏è Error generando t√≠tulo autom√°tico:', titleError);
          // Usar query expandido como fallback mejorado
          generatedTitle = functionArgs.q || message;
        }
      }

      // Detectar tema/grupo para agrupaci√≥n inteligente
      let detectedGroup = null;
      try {
        const groupCompletion = await openai.chat.completions.create({
          model: 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: `Analiza la b√∫squeda y clasif√≠cala en una categor√≠a para agrupaci√≥n inteligente.

CATEGOR√çAS DISPONIBLES:
‚Ä¢ "politica-guatemala" - Temas de gobierno, elecciones, pol√≠ticos guatemaltecos
‚Ä¢ "economia-guatemala" - Temas econ√≥micos, precios, empleo, mercado
‚Ä¢ "deportes-guatemala" - F√∫tbol, olimpiadas, deportes nacionales
‚Ä¢ "cultura-guatemala" - Eventos culturales, festivales, tradiciones
‚Ä¢ "social-guatemala" - Marchas, protestas, movimientos sociales
‚Ä¢ "tecnologia" - Tech, innovaci√≥n, redes sociales
‚Ä¢ "internacional" - Noticias mundiales, pol√≠tica internacional
‚Ä¢ "entretenimiento" - M√∫sica, cine, celebridades
‚Ä¢ "general" - Todo lo dem√°s

INSTRUCCIONES:
‚Ä¢ Devuelve SOLO la categor√≠a, sin explicaciones
‚Ä¢ Si hay duda, usa "general"
‚Ä¢ Prioriza categor√≠as guatemaltecas cuando sea relevante

Query: "${message}"
T√≠tulo generado: "${generatedTitle}"`
            }
          ],
          temperature: 0.1,
          max_tokens: 20
        });

        detectedGroup = groupCompletion.choices[0].message.content.trim().toLowerCase();
        console.log(`üè∑Ô∏è Grupo detectado: "${detectedGroup}"`);
        
      } catch (groupError) {
        console.error('‚ö†Ô∏è Error detectando grupo:', groupError);
        detectedGroup = 'general';
      }

      // Guardar en recent_scrapes con t√≠tulo generado y grupo
      if (toolResult.success && toolResult.tweets) {
        await recentScrapesService.saveScrape({
          queryOriginal: message,
          queryClean: functionArgs.q || message,
          generatedTitle: generatedTitle,
          detectedGroup: detectedGroup,
          herramienta: functionName,
          categoria: 'General',
          tweets: toolResult.tweets,
          userId: userId,
          sessionId: chatSessionId,
          mcpRequestId: requestId,
          mcpExecutionTime: executionTime,
          location: functionArgs.location || 'guatemala'
        });
      }

      // Generar respuesta final con contexto
      const finalCompletion = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: `Eres Vizta, un asistente de investigaci√≥n especializado en an√°lisis social de Guatemala. El usuario hizo una consulta y obtuviste datos usando la herramienta ${functionName}.

INSTRUCCIONES PARA RESPUESTA:
‚Ä¢ S√© CONCISO y DIRECTO (m√°ximo 300 palabras)
‚Ä¢ Usa formato MARKDOWN para mejor legibilidad
‚Ä¢ Estructura tu respuesta con secciones claras
‚Ä¢ Enf√≥cate en lo M√ÅS RELEVANTE, no en todo
‚Ä¢ Usa emojis para hacer m√°s visual la informaci√≥n

FORMATO REQUERIDO:
## üìä An√°lisis de [TEMA]

**üîç B√∫squeda realizada:** [explicar brevemente qu√© se busc√≥]

### üìà Hallazgos principales:
‚Ä¢ [m√°ximo 3 puntos clave]
‚Ä¢ [usar bullets para f√°cil lectura]
‚Ä¢ [incluir datos espec√≠ficos si son relevantes]

### üí≠ Sentimiento general:
[describir en 1-2 l√≠neas el sentimiento predominante]

### ‚ö° Insights clave:
[m√°ximo 2 insights importantes]

### üéØ Conclusi√≥n:
[resumen en 1-2 l√≠neas]

REGLAS IMPORTANTES:
- NO incluyas todos los tweets encontrados
- NO repitas informaci√≥n del prompt de b√∫squeda 
- S√ç menciona los n√∫meros m√°s relevantes (ej: "En 15 tweets analizados...")
- S√ç incluye hashtags o t√©rminos trending si son relevantes
- ENF√ìCATE en el valor para el usuario, no en el proceso t√©cnico

Datos obtenidos: ${JSON.stringify(toolResult, null, 2)}`
          },
          {
            role: 'user',
            content: message
          }
        ],
        temperature: 0.3, // M√°s determin√≠stico para formato consistente
        max_tokens: 600   // Limitar longitud de respuesta
      });

      const finalResponse = finalCompletion.choices[0].message.content;

      // Formatear respuesta para mejor experiencia de usuario
      const formattedResponse = formatChatResponse(finalResponse, toolResult);

      // 6. Guardar respuesta del asistente en memories
      await memoriesService.saveMessage({
        sessionId: chatSessionId,
        userId: userId,
        role: 'assistant',
        content: formattedResponse,
        messageType: 'message',
        tokensUsed: (completion.usage?.total_tokens || 0) + (finalCompletion.usage?.total_tokens || 0),
        modelUsed: 'gpt-4o-mini',
        toolsUsed: [functionName],
        contextSources: toolResult.tweets ? ['twitter'] : [],
        metadata: { 
          requestId: requestId,
          toolArgs: functionArgs,
          executionTime: executionTime,
          toolResult: toolResult.success ? 'success' : 'error',
          responseFormatted: true, // Indicar que se aplic√≥ formato
          generatedTitle: generatedTitle,
          detectedGroup: detectedGroup
        }
      });

      res.json({
        success: true,
        response: formattedResponse,
        toolUsed: functionName,
        toolArgs: functionArgs,
        toolResult: toolResult,
        sessionId: chatSessionId,
        requestId: requestId,
        executionTime: executionTime,
        timestamp: new Date().toISOString(),
        responseMetadata: {
          originalLength: finalResponse.length,
          formattedLength: formattedResponse.length,
          formatApplied: true,
          tweetsAnalyzed: toolResult.tweets_found || 0
        }
      });

    } else {
      // 5. Respuesta directa sin usar herramientas
      const directResponse = assistantMessage.content;
      
      // Formatear respuesta directa tambi√©n
      const formattedDirectResponse = formatChatResponse(directResponse);

      // Guardar respuesta del asistente en memories
      await memoriesService.saveMessage({
        sessionId: chatSessionId,
        userId: userId,
        role: 'assistant',
        content: formattedDirectResponse,
        messageType: 'message',
        tokensUsed: completion.usage?.total_tokens || 0,
        modelUsed: 'gpt-4o-mini',
        toolsUsed: [],
        contextSources: [],
        metadata: { 
          requestId: requestId,
          responseType: 'direct',
          responseFormatted: true
        }
      });

      res.json({
        success: true,
        response: formattedDirectResponse,
        toolUsed: null,
        sessionId: chatSessionId,
        requestId: requestId,
        timestamp: new Date().toISOString(),
        responseMetadata: {
          originalLength: directResponse.length,
          formattedLength: formattedDirectResponse.length,
          formatApplied: true,
          responseType: 'direct'
        }
      });
    }

  } catch (error) {
    console.error('‚ùå Error en consulta Vizta Chat:', error);
    res.status(500).json({
      success: false,
      message: 'Error procesando consulta',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/scrapes
 * Obtener scrapes del usuario
 */
router.get('/scrapes', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const { limit, offset, herramienta, categoria, sessionId } = req.query;

    const scrapes = await recentScrapesService.getUserScrapes(userId, {
      limit: parseInt(limit) || 20,
      offset: parseInt(offset) || 0,
      herramienta,
      categoria,
      sessionId
    });

    res.json({
      success: true,
      scrapes: scrapes,
      count: scrapes.length
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo scrapes:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo scrapes',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/stats
 * Obtener estad√≠sticas de scrapes del usuario
 */
router.get('/stats', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const stats = await recentScrapesService.getUserScrapeStats(userId);

    res.json({
      success: true,
      stats: stats
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo estad√≠sticas:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo estad√≠sticas',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/session/:sessionId
 * Obtener scrapes de una sesi√≥n espec√≠fica
 */
router.get('/session/:sessionId', verifyUserAccess, async (req, res) => {
  try {
    const { sessionId } = req.params;
    const scrapes = await recentScrapesService.getSessionScrapes(sessionId);

    res.json({
      success: true,
      scrapes: scrapes,
      sessionId: sessionId,
      count: scrapes.length
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo scrapes de sesi√≥n:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo scrapes de sesi√≥n',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/tools
 * Obtener herramientas MCP disponibles
 */
router.get('/tools', verifyUserAccess, async (req, res) => {
  try {
    const tools = await mcpService.listAvailableTools();

    res.json({
      success: true,
      tools: tools,
      count: tools.length
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo herramientas MCP:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo herramientas',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/conversations
 * Obtener lista de conversaciones del usuario
 */
router.get('/conversations', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const { limit } = req.query;

    const sessions = await memoriesService.getUserSessions(userId, parseInt(limit) || 20);

    res.json({
      success: true,
      conversations: sessions,
      count: sessions.length
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo conversaciones:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo conversaciones',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/conversation/:sessionId
 * Obtener mensajes de una conversaci√≥n espec√≠fica
 */
router.get('/conversation/:sessionId', verifyUserAccess, async (req, res) => {
  try {
    const { sessionId } = req.params;
    const { limit } = req.query;

    const messages = await memoriesService.getSessionMessages(sessionId, parseInt(limit) || 50);

    res.json({
      success: true,
      messages: messages,
      sessionId: sessionId,
      count: messages.length
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo mensajes de conversaci√≥n:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo mensajes de conversaci√≥n',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/memory-stats
 * Obtener estad√≠sticas de uso de memoria del usuario
 */
router.get('/memory-stats', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const stats = await memoriesService.getUserMemoryStats(userId);

    res.json({
      success: true,
      stats: stats
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo estad√≠sticas de memoria:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo estad√≠sticas de memoria',
      error: error.message
    });
  }
});

/**
 * DELETE /api/vizta-chat/conversation/:sessionId
 * Eliminar una conversaci√≥n completa
 */
router.delete('/conversation/:sessionId', verifyUserAccess, async (req, res) => {
  try {
    const { sessionId } = req.params;
    const userId = req.user.id;

    // Verificar que la sesi√≥n pertenece al usuario
    const messages = await memoriesService.getSessionMessages(sessionId, 1);
    if (messages.length === 0 || messages[0].user_id !== userId) {
      return res.status(404).json({
        success: false,
        message: 'Conversaci√≥n no encontrada'
      });
    }

    // Eliminar todos los mensajes de la sesi√≥n
    const { error } = await supabase
      .from('memories')
      .delete()
      .eq('session_id', sessionId)
      .eq('user_id', userId);

    if (error) {
      throw error;
    }

    res.json({
      success: true,
      message: 'Conversaci√≥n eliminada exitosamente',
      sessionId: sessionId
    });

  } catch (error) {
    console.error('‚ùå Error eliminando conversaci√≥n:', error);
    res.status(500).json({
      success: false,
      message: 'Error eliminando conversaci√≥n',
      error: error.message
    });
  }
});

/**
 * POST /api/vizta-chat/test-expansion
 * Endpoint de prueba para probar la expansi√≥n inteligente de t√©rminos
 */
router.post('/test-expansion', verifyUserAccess, async (req, res) => {
  try {
    const { query } = req.body;
    
    if (!query || typeof query !== 'string' || query.trim().length === 0) {
      return res.status(400).json({
        success: false,
        message: 'El par√°metro "query" es requerido y debe ser un string no vac√≠o'
      });
    }

    // Obtener herramientas disponibles del MCP
    const availableTools = await mcpService.listAvailableTools();
    
    // Simular el proceso de expansi√≥n que har√≠a GPT-4o mini
    const originalQuery = query.trim();
    
    // Usar las funciones de expansi√≥n del MCP para mostrar c√≥mo funcionar√≠an
    console.log(`üß™ Prueba de expansi√≥n para: "${originalQuery}"`);
    
    // Crear un prompt de ejemplo mostrando c√≥mo GPT-4o mini deber√≠a procesar
    const examplePrompt = `USUARIO: "${originalQuery}"

AN√ÅLISIS ESTRAT√âGICO:
1. T√©rminos detectados: ${originalQuery.toLowerCase().split(' ').join(', ')}
2. Contexto inferido: Guatemala, redes sociales
3. Tipo de consulta: ${originalQuery.toLowerCase().includes('sentimiento') || originalQuery.toLowerCase().includes('opinion') ? 'An√°lisis de sentimiento' : 'B√∫squeda de contenido'}

EXPANSI√ìN SUGERIDA:
- Original: "${originalQuery}"
- Expandido: [Se simular√≠a la expansi√≥n aqu√≠]
- Hashtags probables: #Guatemala, #GuatemalaGt
- T√©rminos relacionados: [Se agregar√≠an t√©rminos espec√≠ficos]
- L√≠mite recomendado: ${originalQuery.toLowerCase().includes('sentimiento') ? '20-25 tweets' : '15 tweets'}

HERRAMIENTAS A USAR:
- nitter_context con par√°metros optimizados
- location: guatemala
- limit: optimizado seg√∫n tipo de consulta`;

    res.json({
      success: true,
      test_results: {
        original_query: originalQuery,
        analysis_type: originalQuery.toLowerCase().includes('sentimiento') || originalQuery.toLowerCase().includes('opinion') ? 'sentiment_analysis' : 'content_search',
        suggested_improvements: {
          should_expand_terms: true,
          should_include_hashtags: true,
          should_add_guatemalan_context: true,
          recommended_limit: originalQuery.toLowerCase().includes('sentimiento') ? 20 : 15
        },
        example_prompt: examplePrompt,
        available_tools: availableTools.map(tool => ({
          name: tool.name,
          description: tool.description,
          optimizations_applied: tool.name === 'nitter_context' ? [
            'Expansi√≥n inteligente de t√©rminos',
            'Optimizaci√≥n autom√°tica de l√≠mites',
            'Contexto guatemalteco a√±adido',
            'An√°lisis de sentimiento incluido'
          ] : []
        }))
      },
      instructions: {
        next_steps: [
          'El sistema ahora expandir√° autom√°ticamente los t√©rminos de b√∫squeda',
          'GPT-4o mini usar√° estrategias inteligentes en lugar de t√©rminos literales',
          'Los l√≠mites se optimizar√°n seg√∫n el tipo de an√°lisis',
          'Se incluir√° contexto guatemalteco autom√°ticamente'
        ],
        example_expansions: {
          'marcha del orgullo': 'Orgullo2025 OR MarchadelOrgullo OR OrguIIoGt OR Pride OR LGBTI OR diversidad',
          'elecciones': 'EleccionesGt OR TSE OR voto OR candidatos OR Elecciones2025 OR procesoelectoral',
          'presidente': 'BernardoArevalo OR presidente OR GobiernoGt OR CasaPresidencial OR Presidencia'
        }
      }
    });

  } catch (error) {
    console.error('‚ùå Error en test de expansi√≥n:', error);
    res.status(500).json({
      success: false,
      message: 'Error probando expansi√≥n de t√©rminos',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/scrapes/grouped
 * Obtener scrapes agrupados inteligentemente
 */
router.get('/scrapes/grouped', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const { limit, offset, detectedGroup, categoria } = req.query;

    const groupedScrapes = await recentScrapesService.getGroupedScrapes(userId, {
      limit: parseInt(limit) || 20,
      offset: parseInt(offset) || 0,
      detectedGroup,
      categoria
    });

    res.json({
      success: true,
      groups: groupedScrapes,
      count: groupedScrapes.length,
      metadata: {
        totalGroups: groupedScrapes.length,
        requestedAt: new Date().toISOString()
      }
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo scrapes agrupados:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo scrapes agrupados',
      error: error.message
    });
  }
});

/**
 * GET /api/vizta-chat/scrapes/grouped-stats
 * Obtener estad√≠sticas de agrupaci√≥n
 */
router.get('/scrapes/grouped-stats', verifyUserAccess, async (req, res) => {
  try {
    const userId = req.user.id;
    const stats = await recentScrapesService.getGroupedStats(userId);

    res.json({
      success: true,
      stats: stats,
      generatedAt: new Date().toISOString()
    });

  } catch (error) {
    console.error('‚ùå Error obteniendo estad√≠sticas agrupadas:', error);
    res.status(500).json({
      success: false,
      message: 'Error obteniendo estad√≠sticas agrupadas',
      error: error.message
    });
  }
});

/**
 * DELETE /api/vizta-chat/scrapes/:scrapeId
 * Eliminar un scrape espec√≠fico del usuario
 */
router.delete('/scrapes/:scrapeId', verifyUserAccess, async (req, res) => {
  try {
    const { scrapeId } = req.params;
    const userId = req.user.id;

    // Validar par√°metros
    if (!scrapeId || scrapeId.trim() === '') {
      return res.status(400).json({
        success: false,
        message: 'ID del scrape es requerido'
      });
    }

    console.log(`üóëÔ∏è Solicitud de eliminaci√≥n de scrape ${scrapeId} por usuario ${userId}`);

    // Eliminar scrape usando el servicio
    const result = await recentScrapesService.deleteScrape(scrapeId.trim(), userId);

    res.json({
      success: true,
      message: result.message,
      deletedScrape: result.deletedScrape,
      deletedAt: new Date().toISOString()
    });

  } catch (error) {
    console.error('‚ùå Error eliminando scrape:', error);
    
    // Manejar errores espec√≠ficos
    if (error.message.includes('no encontrado') || error.message.includes('no tienes permisos')) {
      return res.status(404).json({
        success: false,
        message: error.message
      });
    }

    res.status(500).json({
      success: false,
      message: 'Error eliminando scrape',
      error: error.message
    });
  }
});

module.exports = router; 